{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import copy\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import umap\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score,\\\n",
    "f1_score, roc_auc_score, roc_curve, accuracy_score, matthews_corrcoef as mcc\n",
    "from torch.utils.data import Subset\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import Linear\n",
    "from pytorchtools import EarlyStoppingCAC\n",
    "\n",
    "import numbers\n",
    "from sklearn.metrics import davies_bouldin_score as dbs, adjusted_rand_score as ari, silhouette_score\n",
    "from matplotlib import pyplot as plt\n",
    "color = ['grey', 'red', 'blue', 'pink', 'brown', 'black', 'magenta', 'purple', 'orange', 'cyan', 'olive']\n",
    "\n",
    "from models import MultiHeadIDEC,  target_distribution\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     48,
     79,
     118,
     180,
     302,
     331
    ]
   },
   "outputs": [],
   "source": [
    "## Utils.py\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from read_patients import get_aki\n",
    "\n",
    "color = ['grey', 'red', 'blue', 'pink', 'brown', 'black', 'magenta', 'purple', 'orange', 'cyan', 'olive']\n",
    "\n",
    "DATASETS = ['titanic', 'magic', 'creditcard', 'adult', 'diabetes', 'respiratory',\\\n",
    "            'cic', 'sepsis', 'synthetic', 'paper_synthetic', 'kidney', 'infant', 'wid_mortality']\n",
    "\n",
    "DATA_DIR = \"/Users/shivin/Document/NUS/Research/Data\"\n",
    "BASE_DIR = \"/Users/shivin/Document/NUS/Research/cac/cac_dl/DeepCAC\"\n",
    "\n",
    "def load_mnist(path='./data/mnist.npz'):\n",
    "    f = np.load(path)\n",
    "\n",
    "    x_train, y_train, x_test, y_test = f['x_train'], f['y_train'], f[\n",
    "        'x_test'], f['y_test']\n",
    "    f.close()\n",
    "    x = np.concatenate((x_train, x_test))\n",
    "    y = np.concatenate((y_train, y_test)).astype(np.int32)\n",
    "    x = x.reshape((x.shape[0], -1)).astype(np.float32)\n",
    "    x = np.divide(x, 255.)\n",
    "    print('MNIST samples', x.shape)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x, self.y = load_mnist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(np.array(self.x[idx])), torch.from_numpy(\n",
    "            np.array(self.y[idx])), torch.from_numpy(np.array(idx))\n",
    "\n",
    "\n",
    "def load_mnist(path='./data/mnist.npz'):\n",
    "    f = np.load(path)\n",
    "\n",
    "    x_train, y_train, x_test, y_test = f['x_train'], f['y_train'], f[\n",
    "        'x_test'], f['y_test']\n",
    "    f.close()\n",
    "    x = np.concatenate((x_train, x_test))\n",
    "    y = np.concatenate((y_train, y_test)).astype(np.int32)\n",
    "    x = x.reshape((x.shape[0], -1)).astype(np.float32)\n",
    "    x = np.divide(x, 255.)\n",
    "    print('MNIST samples', x.shape)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x, self.y = load_mnist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(np.array(self.x[idx])), torch.from_numpy(\n",
    "            np.array(self.y[idx])), torch.from_numpy(np.array(idx))\n",
    "\n",
    "\n",
    "def is_non_zero_file(fpath):\n",
    "    return os.path.isfile(fpath) and os.path.getsize(fpath) > 0\n",
    "\n",
    "\n",
    "class parameters(object):\n",
    "    def __init__(self, parser):\n",
    "        self.input_dim = -1\n",
    "        self.dataset = parser.dataset\n",
    "        \n",
    "        # Training parameters\n",
    "        self.lr = parser.lr\n",
    "        self.alpha = float(parser.alpha)\n",
    "        self.wd = parser.wd\n",
    "        self.batch_size = parser.batch_size\n",
    "        self.n_epochs = parser.n_epochs\n",
    "        self.pre_epoch = parser.pre_epoch\n",
    "        self.pretrain = parser.pretrain\n",
    "        self.load_ae = parser.load_ae\n",
    "        self.classifier = parser.classifier\n",
    "        self.tol = parser.tol\n",
    "\n",
    "        # Model parameters\n",
    "        self.lamda = parser.lamda\n",
    "        self.beta = parser.beta\n",
    "        self.gamma = parser.gamma\n",
    "        self.delta = parser.delta\n",
    "        self.hidden_dims = parser.hidden_dims\n",
    "        self.latent_dim = self.n_z = parser.n_z\n",
    "        self.n_clusters = parser.n_clusters\n",
    "        self.clustering = parser.clustering\n",
    "        self.n_classes = parser.n_classes\n",
    "\n",
    "        # Utility parameters\n",
    "        self.device = parser.device\n",
    "        self.log_interval = parser.log_interval\n",
    "        self.pretrain_path = parser.pretrain_path + \"/\" + self.dataset + \".pth\"\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Evaluate Critiron\n",
    "#######################################################\n",
    "\n",
    "\n",
    "def cluster_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    row, col = linear_assignment(w.max() - w)\n",
    "    return sum([w[i, j] for i, j in zip(row, col)]) * 1.0 / y_pred.size\n",
    "\n",
    "\n",
    "def plot(model, X_train, y_train, X_test=None, y_test=None, labels=None):\n",
    "    reducer = umap.UMAP(random_state=42)\n",
    "#     idx = torch.Tensor(np.random.randint(0,len(X_train),\\\n",
    "#                         int(0.1*len(X_train)))).type(torch.LongTensor).to(device)\n",
    "    idx = range(int(0.2*len(X_train)))\n",
    "    qs, latents_X = model(X_train[idx], output=\"latent\")\n",
    "    q_train = qs[0]\n",
    "    y_train = y_train[idx]\n",
    "\n",
    "    if labels is not None:\n",
    "        cluster_id_train = labels[idx]\n",
    "    else:\n",
    "        cluster_id_train = torch.argmax(q_train, axis=1)\n",
    "\n",
    "    X2 = reducer.fit_transform(latents_X.cpu().detach().numpy())\n",
    "\n",
    "    print(\"Training data\")\n",
    "\n",
    "    c_clusters = [color[int(cluster_id_train[i])] for i in range(len(cluster_id_train))]\n",
    "    c_labels = [color[int(y_train[i])] for i in range(len(cluster_id_train))]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('Clusters vs Labels')\n",
    "    ax1.scatter(X2[:,0], X2[:,1], color=c_clusters)\n",
    "    ax2.scatter(X2[:,0], X2[:,1], color=c_labels)\n",
    "    plt.show()\n",
    "    if X_test is not None:\n",
    "        qs, latents_test = model(X_test, output=\"latent\")\n",
    "        q_test = qs[0]\n",
    "        X2 = reducer.transform(latents_test.cpu().detach().numpy())\n",
    "        cluster_id_test = torch.argmax(q_test, axis=1)\n",
    "        c_clusters = [color[int(cluster_id_test[i])] for i in range(len(cluster_id_test))]\n",
    "        c_labels = [color[int(y_test[i])] for i in range(len(cluster_id_test))]\n",
    "\n",
    "        print(\"Test data\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.suptitle('Clusters vs Labels')\n",
    "        ax1.scatter(X2[:,0], X2[:,1], color=c_clusters)\n",
    "        ax2.scatter(X2[:,0], X2[:,1], color=c_labels)\n",
    "        plt.show()\n",
    "\n",
    "def get_dataset(DATASET, DATA_DIR):\n",
    "    if DATASET == \"cic\":\n",
    "        Xa = pd.read_csv(DATA_DIR + \"/CIC/cic_set_a.csv\")\n",
    "        Xb = pd.read_csv(DATA_DIR + \"/CIC/cic_set_b.csv\")\n",
    "        Xc = pd.read_csv(DATA_DIR + \"/CIC/cic_set_c.csv\")\n",
    "\n",
    "        ya = Xa['In-hospital_death']\n",
    "        yb = Xb['In-hospital_death']\n",
    "        yc = Xc['In-hospital_death']\n",
    "\n",
    "        Xa = Xa.drop(columns=['recordid', 'Survival', 'In-hospital_death'])\n",
    "        Xb = Xb.drop(columns=['recordid', 'Survival', 'In-hospital_death'])\n",
    "        Xc = Xc.drop(columns=['recordid', 'Survival', 'In-hospital_death'])\n",
    "\n",
    "        cols = Xa.columns\n",
    "\n",
    "        scale = StandardScaler()\n",
    "        Xa = scale.fit_transform(Xa)\n",
    "        Xb = scale.fit_transform(Xb)\n",
    "        Xc = scale.fit_transform(Xc)\n",
    "\n",
    "        Xa = pd.DataFrame(Xa, columns=cols)\n",
    "        Xb = pd.DataFrame(Xb, columns=cols)\n",
    "        Xc = pd.DataFrame(Xc, columns=cols)\n",
    "\n",
    "        Xa = Xa.fillna(0)\n",
    "        Xb = Xb.fillna(0)\n",
    "        Xc = Xc.fillna(0)\n",
    "\n",
    "        X_train = pd.concat([Xa, Xb])\n",
    "        y_train = pd.concat([ya, yb])\n",
    "\n",
    "        X_test = Xc\n",
    "        y_test = yc\n",
    "\n",
    "        X = pd.concat([X_train, X_test]).to_numpy()\n",
    "        y = pd.concat([y_train, y_test]).to_numpy()\n",
    "        columns = cols\n",
    "\n",
    "    elif DATASET == \"titanic\":\n",
    "        X_train = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"X_train.csv\")\n",
    "        columns = X_train.columns\n",
    "        X_train = X_train.to_numpy()\n",
    "        X_test = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"X_test.csv\").to_numpy()\n",
    "        y_train = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"y_train.csv\").to_numpy()\n",
    "        y_test = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"y_test.csv\").to_numpy()\n",
    "\n",
    "        X = np.vstack([X_train, X_test])\n",
    "        y = np.vstack([y_train, y_test])\n",
    "        y1 = []\n",
    "        for i in range(len(y)):\n",
    "            y1.append(y[i][0])\n",
    "        y = np.array(y1)\n",
    "        # X = pd.concat([X_train, X_test]).to_numpy()\n",
    "        # y = pd.concat([y_train, y_test]).to_numpy()\n",
    "    \n",
    "    elif DATASET == \"infant\":\n",
    "        X = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"X.csv\")\n",
    "        columns = X.columns\n",
    "        X = X.to_numpy()\n",
    "        y = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"y.csv\").to_numpy()\n",
    "        y1 = []\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            y1.append(y[i][0])\n",
    "        y = np.array(y1)\n",
    "        y = y.astype(int)\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        X = enc.fit_transform(X).toarray()\n",
    "    \n",
    "    elif DATASET == \"kidney\":\n",
    "        print(\"Fetching Kidney Dataset\")\n",
    "        data = get_aki(DATA_DIR)\n",
    "        X = pd.concat(data,axis=1).T\n",
    "        columns = X.columns\n",
    "\n",
    "        data_columns = list(columns[1:90]) + ['y'] # get the columns which have data, not mask\n",
    "        non_binary_columns = data_columns[:81] # only these columns have non-binary data fit for scaling\n",
    "\n",
    "        X = X.fillna(0)\n",
    "        X = X[data_columns]\n",
    "\n",
    "        y = X['y'].to_numpy().astype(int)\n",
    "        X = X.drop(columns=['y'])\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        X[non_binary_columns] = scaler.fit_transform(np.nan_to_num(X[non_binary_columns]))\n",
    "        X = X.to_numpy()\n",
    "        os.chdir(BASE_DIR)\n",
    "\n",
    "    elif DATASET == \"respiratory\":\n",
    "        print(\"Fetching Respiratory Dataset\")\n",
    "        data = get_aki(DATA_DIR)\n",
    "        X = pd.concat(data,axis=1).T\n",
    "        columns = X.columns\n",
    "\n",
    "        data_columns = list(columns[1:90]) + ['y'] # get the columns which have data, not mask\n",
    "        non_binary_columns = data_columns[:81] # only these columns have non-binary data fit for scaling\n",
    "\n",
    "        X = X.fillna(0)\n",
    "        X = X[data_columns]\n",
    "\n",
    "        y = X['y'].to_numpy().astype(int)\n",
    "        X = X.drop(columns=['y'])\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        X[non_binary_columns] = scaler.fit_transform(np.nan_to_num(X[non_binary_columns]))\n",
    "        X = X.to_numpy()\n",
    "        os.chdir(BASE_DIR)\n",
    "\n",
    "    else:\n",
    "        X = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"X.csv\")\n",
    "        columns = X.columns\n",
    "        X = X.to_numpy()\n",
    "        y = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"y.csv\").to_numpy()\n",
    "        y1 = []\n",
    "        for i in range(len(y)):\n",
    "            y1.append(y[i][0])\n",
    "        y = np.array(y1)\n",
    "    return X, y, columns\n",
    "\n",
    "\n",
    "def create_imbalanced_data_clusters(n_samples=1000, n_features=8, n_informative=5, n_classes=2,\\\n",
    "                            n_clusters = 2, frac=0.4, outer_class_sep=0.5, inner_class_sep=0.2, clus_per_class=2, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    X = np.empty(shape=n_features)\n",
    "    Y = np.empty(shape=1)\n",
    "    offsets = np.random.normal(0, outer_class_sep, size=(n_clusters, n_features))\n",
    "    for i in range(n_clusters):\n",
    "        samples = int(np.random.normal(n_samples, n_samples/10))\n",
    "        x, y = make_classification(n_samples=samples, n_features=n_features, n_informative=n_informative,\\\n",
    "                                    n_classes=n_classes, class_sep=inner_class_sep, n_clusters_per_class=clus_per_class)\n",
    "                                    # n_repeated=0, n_redundant=0)\n",
    "        x += offsets[i]\n",
    "        y_0 = np.where(y == 0)[0]\n",
    "        y_1 = np.where(y != 0)[0]\n",
    "        y_1 = np.random.choice(y_1, int(np.random.normal(frac, frac/4)*len(y_1)))\n",
    "        index = np.hstack([y_0,y_1])\n",
    "        np.random.shuffle(index)\n",
    "        x_new = x[index]\n",
    "        y_new = y[index]\n",
    "\n",
    "        X = np.vstack((X,x_new))\n",
    "        Y = np.hstack((Y,y_new))\n",
    "\n",
    "    X = pd.DataFrame(X[1:,:])\n",
    "    Y = Y[1:]\n",
    "    columns = [\"feature_\"+str(i) for i in range(n_features)]\n",
    "    return X, np.array(Y).astype('int'), columns\n",
    "\n",
    "\n",
    "def get_train_val_test_loaders(args):\n",
    "    if args.dataset in DATASETS:\n",
    "        if args.dataset != \"kidney\" and args.dataset != \"respiratory\":\n",
    "            print(\"Loading Dataset \", args.dataset)\n",
    "            if args.dataset == \"synthetic\":\n",
    "                n_feat = 45\n",
    "                X, y, columns = create_imbalanced_data_clusters(n_samples=5000,\\\n",
    "                       n_clusters=args.n_clusters, n_features = n_feat,\\\n",
    "                       inner_class_sep=0.2, outer_class_sep=2, seed=0)\n",
    "                args.input_dim = n_feat\n",
    "\n",
    "            elif args.dataset == \"paper_synthetic\":\n",
    "                n_feat = 100\n",
    "                X, y = paper_synthetic(2500, centers=4)\n",
    "                args.input_dim = n_feat\n",
    "                print(args.input_dim)\n",
    "\n",
    "            else:\n",
    "                X, y, columns = get_dataset(args.dataset, DATA_DIR)\n",
    "                print(args.dataset)\n",
    "                args.input_dim = X.shape[1]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)\n",
    "\n",
    "            sc = StandardScaler()\n",
    "            X_train = sc.fit_transform(X_train)\n",
    "            X_val = sc.fit_transform(X_val)\n",
    "            X_test = sc.fit_transform(X_test)\n",
    "            X_train_data_loader = list(zip(X_train.astype(np.float32), y_train, range(len(X_train))))\n",
    "            X_val_data_loader = list(zip(X_val.astype(np.float32), y_val, range(len(X_val))))\n",
    "            X_test_data_loader  = list(zip(X_test.astype(np.float32), y_test, range(len(X_train))))\n",
    "\n",
    "        elif args.dataset == \"kidney\":\n",
    "            print(\"Loading Kidney Train\")\n",
    "            X_train, y_train, columns = get_dataset(args.dataset, \"/Users/shivin/Document/NUS/Research/Data/aki/train\")\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)\n",
    "\n",
    "            args.input_dim = X_train.shape[1]\n",
    "            print(args.input_dim)\n",
    "\n",
    "            print(\"Loading Kidney Test\")\n",
    "            X_test, y_test, columns = get_dataset(args.dataset, \"/Users/shivin/Document/NUS/Research/Data/aki/test\")\n",
    "\n",
    "            X_train_data_loader = list(zip(X_train.astype(np.float32), y_train, range(len(X_train))))\n",
    "            X_val_data_loader = list(zip(X_val.astype(np.float32), y_val, range(len(X_val))))\n",
    "            X_test_data_loader  = list(zip(X_test.astype(np.float32), y_test, range(len(X_train))))\n",
    "\n",
    "        else:\n",
    "            print(\"Loading Repiratory Train\")\n",
    "            X_train, y_train, columns = get_dataset(args.dataset, \"/Users/shivin/Document/NUS/Research/Data/ards/train\")\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)\n",
    "\n",
    "            args.input_dim = X_train.shape[1]\n",
    "            print(args.input_dim)\n",
    "\n",
    "            print(\"Loading Respiratory Test\")\n",
    "            X_test, y_test, columns = get_dataset(args.dataset, \"/Users/shivin/Document/NUS/Research/Data/ards/test\")\n",
    "\n",
    "            X_train_data_loader = list(zip(X_train.astype(np.float32), y_train, range(len(X_train))))\n",
    "            X_val_data_loader = list(zip(X_val.astype(np.float32), y_val, range(len(X_val))))\n",
    "            X_test_data_loader  = list(zip(X_test.astype(np.float32), y_test, range(len(X_train))))\n",
    "            \n",
    "        train_loader = torch.utils.data.DataLoader(X_train_data_loader,\n",
    "            batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(X_val_data_loader,\n",
    "            batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(X_test_data_loader, \n",
    "            batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "        return columns, (X_train, y_train, train_loader), (X_val, y_val, val_loader), (X_test, y_test, test_loader)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def paper_synthetic(n_pts=1000, centers=4):\n",
    "    X, y = make_blobs(n_pts, centers=centers)\n",
    "    W = np.random.randn(10,2)\n",
    "    U = np.random.randn(100,10)\n",
    "    X1 = W.dot(X.T)\n",
    "    X1 = X1*(X1>0)\n",
    "    X2 = U.dot(X1)\n",
    "    X2 = X2*(X2>0)\n",
    "    return X2.T, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(start, watch=[]):\n",
    "    from graphviz import Digraph\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    graph = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "\n",
    "    assert(hasattr(start, \"grad_fn\"))\n",
    "    if start.grad_fn is not None:\n",
    "        _draw_graph(loss.grad_fn, graph, watch=watching)\n",
    "\n",
    "    size_per_element = 0.15\n",
    "    min_size = 12\n",
    "\n",
    "    # Get the approximate number of nodes and edges\n",
    "    num_rows = len(graph.body)\n",
    "    content_size = num_rows * size_per_element\n",
    "    size = max(min_size, content_size)\n",
    "    size_str = str(size) + \",\" + str(size)\n",
    "    graph.graph_attr.update(size=size_str)\n",
    "    graph.render(filename='net_graph.jpg')\n",
    "\n",
    "\n",
    "def _draw_graph(var, graph, watch=[], seen=[], indent=\"\", pobj=None):\n",
    "    ''' recursive function going through the hierarchical graph printing off\n",
    "    what we need to see what autograd is doing.'''\n",
    "    from rich import print\n",
    "    \n",
    "    if hasattr(var, \"next_functions\"):\n",
    "        for fun in var.next_functions:\n",
    "            joy = fun[0]\n",
    "            if joy is not None:\n",
    "                if joy not in seen:\n",
    "                    label = str(type(joy)).replace(\n",
    "                        \"class\", \"\").replace(\"'\", \"\").replace(\" \", \"\")\n",
    "                    label_graph = label\n",
    "                    colour_graph = \"\"\n",
    "                    seen.append(joy)\n",
    "\n",
    "                    if hasattr(joy, 'variable'):\n",
    "                        happy = joy.variable\n",
    "                        if happy.is_leaf:\n",
    "                            label += \" \\U0001F343\"\n",
    "                            colour_graph = \"green\"\n",
    "\n",
    "                            for (name, obj) in watch:\n",
    "                                if obj is happy:\n",
    "                                    label += \" \\U000023E9 \" + \\\n",
    "                                        \"[b][u][color=#FF00FF]\" + name + \\\n",
    "                                        \"[/color][/u][/b]\"\n",
    "                                    label_graph += name\n",
    "                                    \n",
    "                                    colour_graph = \"blue\"\n",
    "                                    break\n",
    "\n",
    "                            vv = [str(obj.shape[x])\n",
    "                                  for x in range(len(obj.shape))]\n",
    "                            label += \" [[\"\n",
    "                            label += ', '.join(vv)\n",
    "                            label += \"]]\"\n",
    "                            label += \" \" + str(happy.var())\n",
    "\n",
    "                    graph.node(str(joy), label_graph, fillcolor=colour_graph)\n",
    "                    print(indent + label)\n",
    "                    _draw_graph(joy, graph, watch, seen, indent + \".\", joy)\n",
    "                    if pobj is not None:\n",
    "                        graph.edge(str(pobj), str(joy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     3,
     72
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStoppingCAC:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='./pretrained_model/checkpoint', dataset=\"\", trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = [None, None]\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path + \"_\" + dataset\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = val_loss\n",
    "        if self.best_score[0] is None:\n",
    "            self.best_score[0] = score[0]\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        if self.best_score[1] is None:\n",
    "            self.best_score[1] = score[1]\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        if score[1] < self.best_score[1] + self.delta :\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.ae.state_dict(), self.path+\".pt\")\n",
    "        for j in range(model.n_clusters):\n",
    "            torch.save(model.classifiers[j][0].state_dict(), self.path+\"_\"+str(j)+\".pt\")\n",
    "        self.val_loss_min = val_loss\n",
    "        torch.save(model.cluster_layer, self.path+\"_cc\"+\".pt\")\n",
    "        torch.save(model.p_cluster_layer, self.path+\"_pc\"+\".pt\")\n",
    "        torch.save(model.n_cluster_layer, self.path+\"_nc\"+\".pt\")\n",
    "\n",
    "    def load_checkpoint(self, model):\n",
    "        print(\"Loading Best model with score: \", self.best_score)\n",
    "        model.ae.load_state_dict(torch.load(self.path+\".pt\"))\n",
    "        for j in range(model.n_clusters):\n",
    "            model.classifiers[j][0].load_state_dict(torch.load(self.path+\"_\"+str(j)+\".pt\"))\n",
    "        model.cluster_layer = torch.load(self.path+\"_cc\"+\".pt\")\n",
    "        model.p_cluster_layer = torch.load(self.path+\"_pc\"+\".pt\")\n",
    "        model.n_cluster_layer = torch.load(self.path+\"_nc\"+\".pt\")\n",
    "        return model\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='./pretrained_model/checkpoint', dataset=\"\", trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = [None, None]\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path + \"_\" + dataset\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = val_loss\n",
    "        if self.best_score[0] is None:\n",
    "            self.best_score[0] = score[0]\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        if self.best_score[1] is None:\n",
    "            self.best_score[1] = score[1]\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        if score[1] < self.best_score[1] + self.delta :\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path+\".pt\")\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "    def load_checkpoint(self, model):\n",
    "        print(\"Loading Best model with score: \", self.best_score)\n",
    "        model.load_state_dict(torch.load(self.path+\".pt\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "code_folding": [
     136
    ]
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "import torch\n",
    "from utils import is_non_zero_file\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3,\n",
    "                 input_dim, n_z):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.enc_1 = Linear(input_dim, n_enc_1)\n",
    "        self.enc_2 = Linear(n_enc_1, n_enc_2)\n",
    "        self.enc_3 = Linear(n_enc_2, n_enc_3)\n",
    "\n",
    "        self.z_layer = Linear(n_enc_3, n_z)\n",
    "\n",
    "        # decoder\n",
    "        self.dec_1 = Linear(n_z, n_dec_1)\n",
    "        self.dec_2 = Linear(n_dec_1, n_dec_2)\n",
    "        self.dec_3 = Linear(n_dec_2, n_dec_3)\n",
    "\n",
    "        self.x_bar_layer = Linear(n_dec_3, input_dim)\n",
    "\n",
    "    def forward(self, x, output=\"decoded\"):\n",
    "\n",
    "        # encoder\n",
    "        enc_h1 = F.relu(self.enc_1(x))\n",
    "        enc_h2 = F.relu(self.enc_2(enc_h1))\n",
    "        enc_h3 = F.relu(self.enc_3(enc_h2))\n",
    "\n",
    "        z = self.z_layer(enc_h3)\n",
    "        if output == \"latent\":\n",
    "            return z\n",
    "\n",
    "        # decoder\n",
    "        dec_h1 = F.relu(self.dec_1(z))\n",
    "        dec_h2 = F.relu(self.dec_2(dec_h1))\n",
    "        dec_h3 = F.relu(self.dec_3(dec_h2))\n",
    "        x_bar = self.x_bar_layer(dec_h3)\n",
    "\n",
    "        return x_bar, z\n",
    "\n",
    "\n",
    "def target_distribution(q):\n",
    "    weight = q**2 / q.sum(0)\n",
    "    return (weight.t() / weight.sum(1)).t()\n",
    "\n",
    "\n",
    "def source_distribution(z, cluster_layer, alpha=1):\n",
    "    q = 1.0 / (1.0 + torch.sum(\n",
    "        torch.pow(z.unsqueeze(1) - cluster_layer, 2), 2) / alpha)\n",
    "    q = q.pow((alpha + 1.0) / 2.0)\n",
    "    q = (q.t() / torch.sum(q, 1)).t()\n",
    "    return q\n",
    "\n",
    "\n",
    "# def source_distribution(z, cluster_layer, alpha=1):\n",
    "#     q = 1.0 / (1.0 + torch.sum(\n",
    "#         torch.pow(z.unsqueeze(1) - cluster_layer, 2), 2))\n",
    "#     q = q.pow(2.0 / (alpha - 1.0))\n",
    "#     q = (q.t() / torch.sum(q, 1)).t()\n",
    "#     return q\n",
    "\n",
    "\n",
    "def pretrain_ae(model, train_loader, args):\n",
    "    '''\n",
    "    pretrain autoencoder\n",
    "    '''\n",
    "    print(model)\n",
    "    optimizer = Adam(model.parameters(), lr=args.lr)\n",
    "    for epoch in range(50):\n",
    "        total_loss = 0.\n",
    "        for batch_idx, (x, _, _) in enumerate(train_loader):\n",
    "            x = x.to(args.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            x_bar, _ = model(x)\n",
    "            loss = F.mse_loss(x_bar, x)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Pretraining epoch {} loss={:.4f}\".format(epoch,\n",
    "                                            total_loss / (batch_idx + 1)))\n",
    "        torch.save(model.state_dict(), args.pretrain_path)\n",
    "    print(\"model saved to {}.\".format(args.pretrain_path))\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self, args, input_dim, ae=None):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.args = args\n",
    "        self.n_classes = args.n_classes\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "        self.ae = ae\n",
    "\n",
    "        if self.ae == None:\n",
    "            self.input_dim = args.input_dim\n",
    "        else:\n",
    "            self.input_dim = args.latent_dim\n",
    "        if input_dim != None:\n",
    "            self.input_dim = input_dim\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.input_dim,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.Linear(50, args.n_classes),\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.classifier.parameters(), lr=args.lr)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.ae == None:\n",
    "            return self.classifier(inputs)\n",
    "        else:\n",
    "            input_z = self.ae(inputs, output=\"latent\")\n",
    "            return self.classifier(input_z)\n",
    "\n",
    "    def fit(self, X_batch, y_batch):\n",
    "        self.optimizer.zero_grad()\n",
    "        self.classifier.train()\n",
    "        y_pred = self.forward(X_batch.detach())\n",
    "        train_loss = self.criterion(y_pred, y_batch)\n",
    "        train_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return y_pred.detach().numpy(), train_loss.item()\n",
    "\n",
    "\n",
    "class MultiHeadIDEC(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_enc_1,\n",
    "                 n_enc_2,\n",
    "                 n_enc_3,\n",
    "                 n_dec_1,\n",
    "                 n_dec_2,\n",
    "                 n_dec_3,\n",
    "                 args):\n",
    "        super(MultiHeadIDEC, self).__init__()\n",
    "        self.alpha = args.alpha\n",
    "        self.pretrain_path = args.pretrain_path\n",
    "        self.device = args.device\n",
    "        self.n_clusters = args.n_clusters\n",
    "        self.input_dim = args.input_dim\n",
    "        self.n_z = args.n_z\n",
    "        self.args = args\n",
    "\n",
    "        self.ae = AE(\n",
    "            n_enc_1=n_enc_1,\n",
    "            n_enc_2=n_enc_2,\n",
    "            n_enc_3=n_enc_3,\n",
    "            n_dec_1=n_dec_1,\n",
    "            n_dec_2=n_dec_2,\n",
    "            n_dec_3=n_dec_3,\n",
    "            input_dim=self.input_dim,\n",
    "            n_z=self.n_z)\n",
    "\n",
    "        # cluster layer\n",
    "        self.cluster_layer = torch.Tensor(self.n_clusters, self.n_z)\n",
    "        self.p_cluster_layer = torch.Tensor(self.n_clusters, self.n_z)\n",
    "        self.n_cluster_layer = torch.Tensor(self.n_clusters, self.n_z)\n",
    "        torch.nn.init.xavier_normal_(self.cluster_layer.data)\n",
    "        torch.nn.init.xavier_normal_(self.p_cluster_layer.data)\n",
    "        torch.nn.init.xavier_normal_(self.n_cluster_layer.data)\n",
    "        \n",
    "        self.classifiers = []\n",
    "        for _ in range(self.n_clusters):\n",
    "            classifier = nn.Sequential(\n",
    "                nn.Linear(self.n_z, 64),\n",
    "                nn.ReLU(),\n",
    "                # nn.Linear(128, 64),\n",
    "                # nn.ReLU(),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 8),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(8, args.n_classes),\n",
    "            ).to(self.device)\n",
    "\n",
    "            # classifier = nn.Sequential(\n",
    "            #     nn.Linear(self.n_z, 100),\n",
    "            #     nn.ReLU(),\n",
    "            #     nn.Linear(100, 100),\n",
    "            #     nn.ReLU(),\n",
    "            #     nn.Linear(100, 50),\n",
    "            #     nn.ReLU(),\n",
    "            #     nn.Linear(50, args.n_classes),\n",
    "            # )\n",
    "            optimizer = torch.optim.Adam(classifier.parameters(), lr=args.lr)\n",
    "            self.classifiers.append([classifier, optimizer])\n",
    "            \n",
    "\n",
    "    def pretrain(self, train_loader, path=''):\n",
    "        print(path)\n",
    "        if not is_non_zero_file(path):\n",
    "            path = ''\n",
    "        if path == '':\n",
    "            pretrain_ae(self.ae, train_loader, self.args)\n",
    "        else:\n",
    "            # load pretrain weights\n",
    "            self.ae.load_state_dict(torch.load(self.pretrain_path))\n",
    "            print('load pretrained ae from', path)\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        qs, z_test = self.forward(X_test)\n",
    "        q_test = qs[0]\n",
    "        cluster_ids = torch.argmax(q_test, axis=1)\n",
    "        preds = torch.zeros((self.n_clusters, 2))\n",
    "        for j in range(self.n_clusters):\n",
    "            preds[j,:] = self.classifiers[cluster_ids[j]]\n",
    "        return preds\n",
    "\n",
    "\n",
    "    def forward(self, x, output=\"default\"):\n",
    "        x_bar, z = self.ae(x)\n",
    "        # Cluster\n",
    "        q   = source_distribution(z, self.cluster_layer, alpha=self.alpha)\n",
    "        q_p = source_distribution(z, self.p_cluster_layer, alpha=self.alpha)\n",
    "        q_n = source_distribution(z, self.n_cluster_layer, alpha=self.alpha)\n",
    "\n",
    "        if output == \"latent\":\n",
    "            return (q, q_p, q_n), z\n",
    "\n",
    "        elif output == \"classifier\":\n",
    "            preds = torch.zeros((len(z), 2))\n",
    "            for j in range(len(z)):\n",
    "                preds[j,:] = self.classifiers[j](z)\n",
    "            return preds\n",
    "        \n",
    "        else:\n",
    "            return z, x_bar, (q, q_p, q_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "code_folding": [
     36
    ]
   },
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "params = {\n",
    "'dir' : 'synthetic',\n",
    "'dataset' : 'cic',\n",
    "\n",
    "# Training parameters\n",
    "'lr' : 0.002,\n",
    "'alpha' : 1,\n",
    "'wd' : 5e-4,\n",
    "'batch_size' : 512,\n",
    "'n_epochs' : 50,\n",
    "'pre_epoch' : 40,\n",
    "'pretrain' : True,\n",
    "\"load_ae\": False,\n",
    "\"classifier\": \"LR\",\n",
    "\"tol\": 0.01,\n",
    "\"attention\": \"True\",\n",
    "\n",
    "# Model parameters\n",
    "'lamda' : 1,\n",
    "'beta' : 2, # KL loss/KM loss weight\n",
    "'gamma' : 0.1, # Classification loss weight\n",
    "'delta' : 1, # Class separation weight\n",
    "'hidden_dims' : [64, 32],\n",
    "'n_z' : 20,\n",
    "'n_clusters' : 2,\n",
    "'clustering' : 'cac',\n",
    "'n_classes'  : 2,\n",
    "\n",
    "# Utility parameters\n",
    "'n_jobs' : 6,\n",
    "'device' : 'cpu',\n",
    "'log_interval' : 2,\n",
    "'pretrain_path': '/Users/shivin/Document/NUS/Research/CAC/CAC_DL/DeepCAC/pretrained_model'}\n",
    "# 'pretrain_path': ''}\n",
    "\n",
    "class parameters(object):\n",
    "    def __init__(self, params):\n",
    "        self.dir = params['dir']\n",
    "        self.input_dim = -1\n",
    "        self.dataset = params['dataset']\n",
    "        \n",
    "        # Training parameters\n",
    "        self.lr = params['lr']\n",
    "        self.alpha = params['alpha']\n",
    "        self.wd = params['wd']\n",
    "        self.batch_size = params['batch_size']\n",
    "        self.n_epochs = params['n_epochs']\n",
    "        self.pre_epoch = params['pre_epoch']\n",
    "        self.pretrain = params['pretrain']\n",
    "        self.load_ae = params['load_ae']\n",
    "        self.classifier = params['classifier']\n",
    "        self.tol = params['tol']\n",
    "        self.attention = params['attention'] == \"True\"\n",
    "\n",
    "        # Model parameters\n",
    "        self.lamda = params['lamda']\n",
    "        self.beta = params['beta']\n",
    "        self.gamma = params['gamma']\n",
    "        self.delta = params['delta']\n",
    "        self.hidden_dims = params['hidden_dims']\n",
    "        self.latent_dim = self.n_z = params['n_z']\n",
    "        self.n_clusters = params['n_clusters']\n",
    "        self.clustering = params['clustering']\n",
    "        self.n_classes = params['n_classes']\n",
    "\n",
    "        # Utility parameters\n",
    "        self.n_jobs = params['n_jobs']\n",
    "        self.device = params['device']\n",
    "        self.log_interval = params['log_interval']\n",
    "        self.pretrain_path = params['pretrain_path'] + \"/\" + self.dataset + \".pth\"\n",
    "\n",
    "args = parameters(params)\n",
    "datasets = ['titanic', 'magic', 'creditcard', 'adult', 'diabetes',\\\n",
    "            'cic', 'sepsis', 'synthetic', 'paper_synthetic', 'kidney', 'infant', 'wid_mortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset  cic\n",
      "cic\n"
     ]
    }
   ],
   "source": [
    "suffix = \"\"\n",
    "suffix += args.dataset + \"_\"\n",
    "suffix += str(args.n_clusters) + \"_\"\n",
    "suffix += str(args.attention)\n",
    "\n",
    "column_names, train_data, val_data, test_data = get_train_val_test_loaders(args)\n",
    "os.chdir(BASE_DIR)\n",
    "X_train, y_train, train_loader = train_data\n",
    "X_val, y_val, val_loader = val_data\n",
    "X_test, y_test, test_loader = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "(6750, 117)\n",
      "0.14133333333333334\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train)+len(X_val)+len(X_test))\n",
    "print(X_train.shape)\n",
    "print(sum(y_train)/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_kidney = X_train\n",
    "# y_train_kidney = y_train\n",
    "# train_loader_kidney = train_loader\n",
    "# X_val_kidney = X_val\n",
    "# y_val_kidney = y_val\n",
    "# val_loader_kidney = val_loader\n",
    "# X_test_kidney = X_test\n",
    "# y_test_kidney = y_test\n",
    "# test_loader_kidney = test_loader\n",
    "X_train = X_train_kidney\n",
    "y_train = y_train_kidney\n",
    "# train_loader = train_loader_kidney\n",
    "X_val = X_val_kidney\n",
    "y_val = y_val_kidney\n",
    "# val_loader = val_loader_kidney\n",
    "X_test = X_test_kidney\n",
    "y_test = y_test_kidney\n",
    "# test_loader = test_loader_kidney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_resp = X_train\n",
    "# y_train_resp = y_train\n",
    "# train_loader_resp = train_loader\n",
    "# X_val_resp = X_val\n",
    "# y_val_resp = y_val\n",
    "# val_loader_resp = val_loader\n",
    "# X_test_resp = X_test\n",
    "# y_test_resp = y_test\n",
    "# test_loader_resp = test_loader\n",
    "X_train = X_train_resp\n",
    "y_train = y_train_resp\n",
    "train_loader = train_loader_resp\n",
    "X_val = X_val_resp\n",
    "y_val = y_val_resp\n",
    "val_loader = val_loader_resp\n",
    "X_test = X_test_resp\n",
    "y_test = y_test_resp\n",
    "test_loader = test_loader_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SAPS-I', 'SOFA', 'Length_of_stay', 'Age', 'Gender', 'Height', 'Weight',\n",
      "       'CCU', 'CSRU', 'SICU',\n",
      "       ...\n",
      "       'SysABP_last', 'TroponinI_last', 'TroponinT_last', 'WBC_last',\n",
      "       'Weight_last', 'pH_last', 'MechVentStartTime', 'MechVentDuration',\n",
      "       'MechVentLast8Hour', 'UrineOutputSum'],\n",
      "      dtype='object', length=117)\n",
      "(6750, 117)\n"
     ]
    }
   ],
   "source": [
    "print(column_names)\n",
    "args.input_dim = X_train.shape[1]\n",
    "BASE_DIR = \"/Users/shivin/Document/NUS/Research/cac/cac_dl/DeepCAC\"\n",
    "os.chdir(BASE_DIR)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiHead IDEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "code_folding": [
     37
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shivin/Document/NUS/Research/CAC/CAC_DL/DeepCAC/pretrained_model/cic.pth\n",
      "load pretrained ae from /Users/shivin/Document/NUS/Research/CAC/CAC_DL/DeepCAC/pretrained_model/cic.pth\n"
     ]
    }
   ],
   "source": [
    "model = MultiHeadIDEC(\n",
    "        n_enc_1=128,\n",
    "        n_enc_2=64,\n",
    "        n_enc_3=32,\n",
    "        n_dec_1=32,\n",
    "        n_dec_2=64,\n",
    "        n_dec_3=128,\n",
    "        args=args).to(args.device)\n",
    "\n",
    "model.pretrain(train_loader, args.pretrain_path)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# cluster parameter initiate\n",
    "device = args.device\n",
    "y = y_train\n",
    "_, ori_hidden = model.ae(torch.Tensor(X_train).to(args.device))\n",
    "_, ori_hidden_val = model.ae(torch.Tensor(X_val).to(args.device))\n",
    "\n",
    "kmeans = KMeans(n_clusters=args.n_clusters, n_init=20)\n",
    "_ = kmeans.fit_predict(ori_hidden.data.cpu().numpy())\n",
    "\n",
    "ori_cluster_indices = kmeans.labels_\n",
    "original_cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "ori_val_cluster_indices = kmeans.fit_predict(ori_hidden_val.data.cpu().numpy())\n",
    "\n",
    "model.cluster_layer.data = torch.tensor(original_cluster_centers).to(device)\n",
    "\n",
    "## Initialization ##\n",
    "for i in range(args.n_clusters):\n",
    "    cluster_idx = np.where(ori_cluster_indices == i)[0]\n",
    "    cluster_idx_p = np.where(y[cluster_idx] == 1)[0]\n",
    "    cluster_idx_n = np.where(y[cluster_idx] == 0)[0]\n",
    "    hidden_p = ori_hidden[cluster_idx][cluster_idx_p]\n",
    "    hidden_n = ori_hidden[cluster_idx][cluster_idx_n]\n",
    "\n",
    "    model.p_cluster_layer.data[i,:] = torch.mean(hidden_p, axis=0)\n",
    "    model.n_cluster_layer.data[i,:] = torch.mean(hidden_n, axis=0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "code_folding": [
     157
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "qval tensor([1673.4197,  576.5802], grad_fn=<SumBackward1>)\n",
      "qval max [1896  354]\n",
      "\n",
      "[ 0/50] train_loss: 5761.388 valid_loss: 1863.317 valid_F1: 0.252 valid_AUC: 0.511 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "Epoch: 00 | Loss: 513.458 | Classification Loss: 4629.346 | Cluster Balance Loss: 2.739\n",
      "Epoch: 01 | Loss: 379.967 | Classification Loss: 3456.179 | Cluster Balance Loss: 0.853\n",
      "qval tensor([1080.7876, 1169.2124], grad_fn=<SumBackward1>)\n",
      "qval max [ 989 1261]\n",
      "\n",
      "[ 2/50] train_loss: 2551.296 valid_loss: 788.632 valid_F1: 0.059 valid_AUC: 0.816 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "Epoch: 02 | Loss: 265.543 | Classification Loss: 2277.242 | Cluster Balance Loss: 0.741\n",
      "Epoch: 03 | Loss: 232.710 | Classification Loss: 2004.034 | Cluster Balance Loss: 0.697\n",
      "qval tensor([1161.5186, 1088.4814], grad_fn=<SumBackward1>)\n",
      "qval max [1250 1000]\n",
      "\n",
      "[ 4/50] train_loss: 1887.741 valid_loss: 666.362 valid_F1: 0.362 valid_AUC: 0.839 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "Epoch: 04 | Loss: 217.838 | Classification Loss: 1887.576 | Cluster Balance Loss: 0.434\n",
      "Epoch: 05 | Loss: 204.031 | Classification Loss: 1776.062 | Cluster Balance Loss: 0.495\n",
      "qval tensor([1104.6985, 1145.3015], grad_fn=<SumBackward1>)\n",
      "qval max [1160 1090]\n",
      "\n",
      "[ 6/50] train_loss: 1689.169 valid_loss: 661.434 valid_F1: 0.449 valid_AUC: 0.851 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "Epoch: 06 | Loss: 193.628 | Classification Loss: 1682.897 | Cluster Balance Loss: 0.503\n",
      "Epoch: 07 | Loss: 179.827 | Classification Loss: 1561.958 | Cluster Balance Loss: 0.375\n",
      "qval tensor([1018.1370, 1231.8630], grad_fn=<SumBackward1>)\n",
      "qval max [1047 1203]\n",
      "\n",
      "[ 8/50] train_loss: 1596.586 valid_loss: 715.664 valid_F1: 0.520 valid_AUC: 0.840 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 08 | Loss: 165.828 | Classification Loss: 1422.212 | Cluster Balance Loss: 0.449\n",
      "Epoch: 09 | Loss: 153.933 | Classification Loss: 1298.800 | Cluster Balance Loss: 1.244\n",
      "qval tensor([1242.3125, 1007.6875], grad_fn=<SumBackward1>)\n",
      "qval max [1514  736]\n",
      "\n",
      "[10/50] train_loss: 1191.799 valid_loss: 764.977 valid_F1: 0.440 valid_AUC: 0.833 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 10 | Loss: 139.972 | Classification Loss: 1171.070 | Cluster Balance Loss: 0.927\n",
      "Epoch: 11 | Loss: 123.610 | Classification Loss: 1020.357 | Cluster Balance Loss: 0.661\n",
      "qval tensor([1095.0117, 1154.9882], grad_fn=<SumBackward1>)\n",
      "qval max [1016 1234]\n",
      "\n",
      "[12/50] train_loss: 903.325 valid_loss: 851.493 valid_F1: 0.484 valid_AUC: 0.826 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch: 12 | Loss: 112.882 | Classification Loss: 920.806 | Cluster Balance Loss: 0.667\n",
      "Epoch: 13 | Loss: 97.727 | Classification Loss: 778.873 | Cluster Balance Loss: 0.557\n",
      "qval tensor([1172.1771, 1077.8229], grad_fn=<SumBackward1>)\n",
      "qval max [1235 1015]\n",
      "\n",
      "[14/50] train_loss: 784.868 valid_loss: 1076.777 valid_F1: 0.417 valid_AUC: 0.802 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch: 14 | Loss: 90.597 | Classification Loss: 707.333 | Cluster Balance Loss: 0.702\n",
      "Epoch: 15 | Loss: 77.239 | Classification Loss: 583.762 | Cluster Balance Loss: 0.346\n",
      "qval tensor([1122.3282, 1127.6718], grad_fn=<SumBackward1>)\n",
      "qval max [1044 1206]\n",
      "\n",
      "[16/50] train_loss: 526.880 valid_loss: 1142.287 valid_F1: 0.496 valid_AUC: 0.815 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch: 16 | Loss: 66.877 | Classification Loss: 480.485 | Cluster Balance Loss: 0.432\n",
      "Epoch: 17 | Loss: 62.264 | Classification Loss: 441.828 | Cluster Balance Loss: 0.427\n",
      "qval tensor([1096.9041, 1153.0959], grad_fn=<SumBackward1>)\n",
      "qval max [ 983 1267]\n",
      "\n",
      "[18/50] train_loss: 349.167 valid_loss: 1213.060 valid_F1: 0.495 valid_AUC: 0.814 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch: 18 | Loss: 51.004 | Classification Loss: 332.450 | Cluster Balance Loss: 0.270\n",
      "Epoch: 19 | Loss: 50.116 | Classification Loss: 327.636 | Cluster Balance Loss: 0.338\n",
      "qval tensor([1130.3308, 1119.6692], grad_fn=<SumBackward1>)\n",
      "qval max [1143 1107]\n",
      "\n",
      "[20/50] train_loss: 215.609 valid_loss: 1323.005 valid_F1: 0.460 valid_AUC: 0.811 valid_Feature_p: 0.000 valid_Silhouette: 0.000\n",
      "EarlyStopping counter: 7 out of 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training\")\n",
    "model.train()\n",
    "# to track the training loss as the model trains\n",
    "train_losses = []\n",
    "# to track the validation loss as the model trains\n",
    "valid_losses = []\n",
    "# to track the average training loss per epoch as the model trains\n",
    "avg_train_losses = []\n",
    "# to track the average validation loss per epoch as the model trains\n",
    "avg_valid_losses = []\n",
    "\n",
    "N_EPOCHS = args.n_epochs\n",
    "es = EarlyStoppingCAC(dataset=suffix)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if epoch % args.log_interval == 0:\n",
    "        # blockPrint()\n",
    "        model.ae.eval() # prep model for evaluation\n",
    "        for j in range(model.n_clusters):\n",
    "            model.classifiers[j][0].eval()\n",
    "\n",
    "        z_train, _, q_train = model(torch.Tensor(X_train).to(args.device), output=\"decoded\")\n",
    "        q_train, q_train_p, q_train_n = q_train\n",
    "        # update target distribution p\n",
    "        q_train = q_train.data\n",
    "\n",
    "        # evaluate clustering performance\n",
    "        cluster_indices = q_train.cpu().numpy().argmax(1)\n",
    "\n",
    "        # Calculate Training Metrics\n",
    "        nmi, acc, ari = 0, 0, 0\n",
    "        train_loss = 0\n",
    "        for j in range(args.n_clusters):\n",
    "            # kmeans = KMeans(n_clusters=args.n_classes, n_init=20)\n",
    "            cluster_idx = np.where(cluster_indices == j)[0]\n",
    "            # y_pred_idx = kmeans.fit_predict(z_train.data.cpu().numpy()[cluster_idx])\n",
    "            # nmi_k = nmi_score(y_pred_idx, y[cluster_idx])\n",
    "            # nmi += nmi_k * len(cluster_idx)/len(X_train)\n",
    "            # acc += cluster_acc(y_pred_idx, y[cluster_idx]) * len(cluster_idx)/len(X_train)\n",
    "            # ari += ari_score(y_pred_idx, y[cluster_idx]) * len(cluster_idx)/len(X_train)\n",
    "\n",
    "            X_cluster = z_train[cluster_idx]\n",
    "            y_cluster = torch.Tensor(y_train[cluster_idx]).type(torch.LongTensor).to(model.device)\n",
    "\n",
    "            classifier_k, optimizer_k = model.classifiers[j]\n",
    "            y_pred_cluster = classifier_k(X_cluster)\n",
    "            cluster_los = criterion(y_pred_cluster, y_cluster)\n",
    "            train_loss += cluster_los\n",
    "\n",
    "        # Evaluate model on Test dataset\n",
    "        qs, z_val = model(torch.FloatTensor(X_val).to(args.device), output=\"latent\")\n",
    "        q_val = qs[0]\n",
    "        cluster_ids = torch.argmax(q_val, axis=1)\n",
    "        preds = torch.zeros((len(z_val), 2))\n",
    "\n",
    "        # Weighted predictions\n",
    "        if args.attention == False:\n",
    "            for j in range(model.n_clusters):\n",
    "                cluster_id = np.where(cluster_ids == j)[0]\n",
    "                X_cluster = z_val[cluster_id]\n",
    "                cluster_preds_val = model.classifiers[j][0](X_cluster)\n",
    "                preds[cluster_id,:] = cluster_preds_val\n",
    "\n",
    "        else:\n",
    "            for j in range(model.n_clusters):\n",
    "                cluster_id = np.where(cluster_ids == j)[0]\n",
    "                X_cluster = z_val\n",
    "                cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "                preds[:,0] += q_val[:,j]*cluster_preds[:,0]\n",
    "                preds[:,1] += q_val[:,j]*cluster_preds[:,1]\n",
    "\n",
    "        feature_diff = 0\n",
    "        cntr = 0\n",
    "        for i in range(args.n_clusters):\n",
    "            for j in range(args.n_clusters):\n",
    "                if i > j:\n",
    "                    ci = torch.where(cluster_ids == i)[0]\n",
    "                    cj = torch.where(cluster_ids == j)[0]\n",
    "                    Xi = X_val[ci]\n",
    "                    Xj = X_val[cj]\n",
    "                    # feature_diff += sum(ttest_ind(Xi, Xj, axis=0)[1] < 0.05)/args.input_dim\n",
    "                    # print(\"Cluster [{}, {}] p-value: \".format(i,j), feature_diff)\n",
    "                    cntr += 1\n",
    "\n",
    "        print(\"qval\", torch.sum(q_val, axis=0))\n",
    "        print(\"qval max\", np.bincount(cluster_ids))\n",
    "        # print(\"KL div\", torch.kl_div(torch.sum(q_val, axis=0),\\\n",
    "        #                         torch.ones(args.n_clusters)/args.n_clusters))\n",
    "        # val_sil = silhouette_score(z_val.data.cpu().numpy(), cluster_ids.data.cpu().numpy(), metric='euclidean')\n",
    "        val_sil = 0\n",
    "        val_f1  = f1_score(y_val, np.argmax(preds.detach().numpy(), axis=1))\n",
    "        val_auc = roc_auc_score(y_val, preds[:,1].detach().numpy())\n",
    "        val_feature_diff = feature_diff/cntr\n",
    "\n",
    "        loss = criterion(preds, torch.Tensor(y_val).type(torch.LongTensor))\n",
    "        # record validation loss\n",
    "        valid_losses.append(loss.item())\n",
    "\n",
    "        # calculate average loss over an epoch\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        epoch_len = len(str(N_EPOCHS))\n",
    "\n",
    "        print_msg = (f'\\n[{epoch:>{epoch_len}}/{N_EPOCHS:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.3f} ' +\n",
    "                     f'valid_loss: {valid_loss:.3f} '  +\n",
    "                     f'valid_F1: {val_f1:.3f} '  +\n",
    "                     f'valid_AUC: {val_auc:.3f} ' + \n",
    "                     f'valid_Feature_p: {val_feature_diff:.3f} ' + \n",
    "                     f'valid_Silhouette: {val_sil:.3f}')\n",
    "\n",
    "        print(print_msg)\n",
    "\n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        es([val_f1, val_auc], model)\n",
    "        if es.early_stop == True:\n",
    "            break\n",
    "\n",
    "    # Normal Training\n",
    "    epoch_loss = 0\n",
    "    epoch_balance_loss = 0\n",
    "    epoch_class_loss = 0\n",
    "\n",
    "    model.ae.train() # prep model for evaluation\n",
    "    for j in range(model.n_clusters):\n",
    "        model.classifiers[j][0].train()\n",
    "\n",
    "    for batch_idx, (x_batch, y_batch, idx) in enumerate(train_loader):\n",
    "        # torch.autograd.set_detect_anomaly(True)\n",
    "        x_batch = x_batch.to(device)\n",
    "        idx = idx.to(device)\n",
    "\n",
    "        X_latents, x_bar, q_train = model(x_batch)\n",
    "        q_train, q_train_p, q_train_n = q_train\n",
    "        reconstr_loss = F.mse_loss(x_bar, x_batch)\n",
    "\n",
    "        classifier_labels = np.zeros(len(idx))\n",
    "        sub_epochs = min(1, 10 - int(epoch/5))\n",
    "        # sub_epochs = 10\n",
    "        if args.attention == False:\n",
    "            classifier_labels = np.argmax(q_train.detach().cpu().numpy(), axis=1)\n",
    "\n",
    "        for _ in range(sub_epochs):\n",
    "            # Choose classifier for a point probabilistically\n",
    "            if args.attention == True:\n",
    "                for j in range(len(idx)):\n",
    "                    classifier_labels[j] = np.random.choice(range(args.n_clusters), p = q_train[j].detach().numpy())\n",
    "\n",
    "            for k in range(args.n_clusters):\n",
    "                idx_cluster = np.where(classifier_labels == k)[0]\n",
    "                X_cluster = X_latents[idx_cluster]\n",
    "                y_cluster = y_batch[idx_cluster]\n",
    "\n",
    "                classifier_k, optimizer_k = model.classifiers[k]\n",
    "                # Do not backprop the error to encoder\n",
    "                y_pred_cluster = classifier_k(X_cluster.detach())\n",
    "                cluster_loss = criterion(y_pred_cluster, y_cluster)\n",
    "                optimizer_k.zero_grad()\n",
    "                cluster_loss.backward(retain_graph=True)\n",
    "                optimizer_k.step()\n",
    "\n",
    "        class_loss = torch.tensor(0.).to(args.device)\n",
    "        for k in range(args.n_clusters):\n",
    "            idx_cluster = np.where(classifier_labels == k)[0]\n",
    "            X_cluster = X_latents[idx_cluster]\n",
    "            y_cluster = y_batch[idx_cluster]\n",
    "\n",
    "            classifier_k, optimizer_k = model.classifiers[k]\n",
    "            y_pred_cluster = classifier_k(X_cluster)\n",
    "            cluster_los = criterion(y_pred_cluster, y_cluster)\n",
    "            class_loss += cluster_los\n",
    "\n",
    "        delta_mu   = torch.zeros((args.n_clusters, args.latent_dim)).to(args.device)\n",
    "        cluster_id = torch.argmax(q_train, 1)\n",
    "\n",
    "        km_loss             = 0\n",
    "        cluster_balance_loss = 0\n",
    "\n",
    "        for j in range(args.n_clusters):\n",
    "            pts_index = np.where(cluster_id == j)[0]\n",
    "            cluster_pts = X_latents[pts_index]\n",
    "            delta_mu[j,:]   = cluster_pts.sum(axis=0)/(1+len(cluster_pts))\n",
    "            km_loss += torch.linalg.vector_norm(X_latents[pts_index] - model.cluster_layer[j])/(1+len(cluster_pts))\n",
    "\n",
    "        q_train = source_distribution(X_latents, model.cluster_layer, alpha=model.alpha)\n",
    "        P = torch.sum(torch.nn.Softmax(dim=1)(10*q_train), axis=0)\n",
    "        P = P/P.sum()\n",
    "        Q = torch.ones(args.n_clusters)/args.n_clusters # Uniform distribution\n",
    "\n",
    "        # cluster_balance_loss = F.kl_div(P.log(), Q, reduction='batchmean')\n",
    "        cluster_balance_loss = torch.linalg.vector_norm(torch.sqrt(P) - torch.sqrt(Q))\n",
    "\n",
    "        loss = reconstr_loss\n",
    "        if args.beta != 0:\n",
    "            loss += args.beta*km_loss\n",
    "        if args.gamma != 0:\n",
    "            loss += args.gamma*class_loss\n",
    "        if args.delta != 0:\n",
    "            loss += args.delta*cluster_balance_loss\n",
    "\n",
    "        epoch_loss += loss\n",
    "        epoch_balance_loss += cluster_balance_loss\n",
    "        epoch_class_loss += class_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the positive and negative centroids\n",
    "        for j in range(args.n_clusters):\n",
    "            pts_index = np.where(cluster_id == j)[0]\n",
    "            N  = len(pts_index)\n",
    "            model.cluster_layer.data[j:]   -= (1/(100+N))*delta_mu[j:]\n",
    "\n",
    "    print('Epoch: {:02d} | Loss: {:.3f} | Classification Loss: {:.3f} | Cluster Balance Loss: {:.3f}'.format(\n",
    "                epoch, epoch_loss, epoch_class_loss, epoch_balance_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################\n",
      "\n",
      "Training Local Networks\n",
      "Loading Best model with score:  [0.449064449064449, 0.8509266733266733]\n",
      "\n",
      "[20/50] train_loss: 1673.633 valid_loss: 651.273 valid_F1: 0.505 valid_AUC: 0.850\n",
      "\n",
      "[20/50] train_loss: 1659.695 valid_loss: 654.874 valid_F1: 0.508 valid_AUC: 0.850\n",
      "\n",
      "[20/50] train_loss: 1653.413 valid_loss: 654.964 valid_F1: 0.519 valid_AUC: 0.858\n",
      "\n",
      "[20/50] train_loss: 1640.625 valid_loss: 655.608 valid_F1: 0.515 valid_AUC: 0.854\n",
      "EarlyStopping counter: 1 out of 7\n",
      "\n",
      "[20/50] train_loss: 1629.343 valid_loss: 655.212 valid_F1: 0.516 valid_AUC: 0.850\n",
      "EarlyStopping counter: 2 out of 7\n",
      "\n",
      "[20/50] train_loss: 1618.674 valid_loss: 654.949 valid_F1: 0.526 valid_AUC: 0.853\n",
      "EarlyStopping counter: 3 out of 7\n",
      "\n",
      "[20/50] train_loss: 1607.958 valid_loss: 654.795 valid_F1: 0.525 valid_AUC: 0.845\n",
      "EarlyStopping counter: 4 out of 7\n",
      "\n",
      "[20/50] train_loss: 1603.345 valid_loss: 654.622 valid_F1: 0.518 valid_AUC: 0.858\n",
      "\n",
      "[20/50] train_loss: 1598.278 valid_loss: 654.386 valid_F1: 0.524 valid_AUC: 0.845\n",
      "EarlyStopping counter: 1 out of 7\n",
      "\n",
      "[20/50] train_loss: 1595.397 valid_loss: 654.118 valid_F1: 0.518 valid_AUC: 0.852\n",
      "EarlyStopping counter: 2 out of 7\n",
      "\n",
      "[20/50] train_loss: 1592.931 valid_loss: 653.567 valid_F1: 0.517 valid_AUC: 0.846\n",
      "EarlyStopping counter: 3 out of 7\n",
      "\n",
      "[20/50] train_loss: 1591.616 valid_loss: 653.622 valid_F1: 0.501 valid_AUC: 0.847\n",
      "EarlyStopping counter: 4 out of 7\n",
      "\n",
      "[20/50] train_loss: 1587.492 valid_loss: 653.659 valid_F1: 0.514 valid_AUC: 0.848\n",
      "EarlyStopping counter: 5 out of 7\n",
      "\n",
      "[20/50] train_loss: 1592.216 valid_loss: 653.239 valid_F1: 0.528 valid_AUC: 0.853\n",
      "EarlyStopping counter: 6 out of 7\n",
      "\n",
      "[20/50] train_loss: 1587.729 valid_loss: 653.302 valid_F1: 0.497 valid_AUC: 0.847\n",
      "EarlyStopping counter: 7 out of 7\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n####################################################################################\\n\")\n",
    "print(\"Training Local Networks\")\n",
    "model = es.load_checkpoint(model)\n",
    "\n",
    "es = EarlyStoppingCAC(dataset=suffix)\n",
    "\n",
    "qs, z_train = model(torch.FloatTensor(np.array(X_train)).to(args.device), output=\"latent\")\n",
    "q_train = qs[0]\n",
    "cluster_id_train = torch.argmax(q_train, axis=1)\n",
    "\n",
    "# X_latents_data_loader = list(zip(z_train, cluster_id_train, y_train))\n",
    "X_latents_data_loader = list(zip(z_train.to(args.device),q_train, y_train))\n",
    "\n",
    "train_loader_latents = torch.utils.data.DataLoader(X_latents_data_loader,\n",
    "    batch_size=1024, shuffle=False)\n",
    "\n",
    "B = []\n",
    "\n",
    "# plot(model, torch.FloatTensor(np.array(X_train)).to(args.device), y_train,\\\n",
    "#      torch.FloatTensor(np.array(X_test)).to(args.device), y_test)\n",
    "\n",
    "# Post clustering training\n",
    "for e in range(N_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1 = 0\n",
    "    acc = 0\n",
    "\n",
    "    # model.ae.train() # prep model for evaluation\n",
    "    for j in range(model.n_clusters):\n",
    "        model.classifiers[j][0].train()\n",
    "\n",
    "    # Full training of local networks\n",
    "    for batch_idx, (X_latents, q_batch, y_batch) in enumerate(train_loader_latents):\n",
    "        # torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "        classifier_labels = np.zeros(len(X_latents))\n",
    "        # Choose classifier for a point probabilistically\n",
    "        if args.attention == True:\n",
    "            for j in range(len(X_latents)):\n",
    "                classifier_labels[j] = np.random.choice(range(args.n_clusters), p = q_batch[j].detach().numpy())\n",
    "        else:\n",
    "            classifier_labels = torch.argmax(q_batch, axis=1).data.cpu().numpy()\n",
    "        for k in range(args.n_clusters):\n",
    "            idx_cluster = np.where(classifier_labels == k)[0]\n",
    "            X_cluster = X_latents[idx_cluster]\n",
    "            B.append(torch.max(torch.linalg.norm(X_cluster, axis=1)))\n",
    "            y_cluster = y_batch[idx_cluster]\n",
    "\n",
    "            classifier_k, optimizer_k = model.classifiers[k]\n",
    "            # Do not backprop the error to encoder\n",
    "            y_pred_cluster = classifier_k(X_cluster.detach())\n",
    "            cluster_loss = criterion(y_pred_cluster, y_cluster)\n",
    "            optimizer_k.zero_grad()\n",
    "            cluster_loss.backward(retain_graph=True)\n",
    "            optimizer_k.step()\n",
    "\n",
    "    # model.ae.eval() # prep model for evaluation\n",
    "    for j in range(model.n_clusters):\n",
    "        model.classifiers[j][0].eval()\n",
    "\n",
    "    preds = torch.zeros((len(z_train), 2))\n",
    "\n",
    "    # Weighted predictions\n",
    "    for j in range(model.n_clusters):\n",
    "        cluster_id = np.where(classifier_labels == j)[0]\n",
    "        X_cluster = z_train\n",
    "        cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "        preds[:,0] += q_train[:,j]*cluster_preds[:,0]\n",
    "        preds[:,1] += q_train[:,j]*cluster_preds[:,1]\n",
    "\n",
    "    train_loss = criterion(preds, torch.Tensor(y_train).type(torch.LongTensor))\n",
    "\n",
    "    # Evaluate model on Validation set\n",
    "    qs, z_val = model(torch.FloatTensor(X_val).to(args.device), output=\"latent\")\n",
    "    q_val = qs[0]\n",
    "    cluster_ids = torch.argmax(q_val, axis=1)\n",
    "    preds = torch.zeros((len(z_val), 2))\n",
    "\n",
    "    # Weighted predictions\n",
    "    for j in range(model.n_clusters):\n",
    "        cluster_id = np.where(cluster_ids == j)[0]\n",
    "        X_cluster = z_val\n",
    "        cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "        preds[:,0] += q_val[:,j]*cluster_preds[:,0]\n",
    "        preds[:,1] += q_val[:,j]*cluster_preds[:,1]\n",
    "\n",
    "    val_f1  = f1_score(y_val, np.argmax(preds.detach().numpy(), axis=1))\n",
    "    val_auc = roc_auc_score(y_val, preds[:,1].detach().numpy())\n",
    "\n",
    "    loss = criterion(preds, torch.Tensor(y_val).type(torch.LongTensor))\n",
    "    # record validation loss\n",
    "    valid_losses.append(loss.item())\n",
    "\n",
    "    # calculate average loss over an epoch\n",
    "    valid_loss = np.average(valid_losses)\n",
    "    avg_valid_losses.append(valid_loss)\n",
    "\n",
    "    epoch_len = len(str(N_EPOCHS))\n",
    "\n",
    "    print_msg = (f'\\n[{epoch:>{epoch_len}}/{N_EPOCHS:>{epoch_len}}] ' +\n",
    "                 f'train_loss: {train_loss:.3f} ' +\n",
    "                 f'valid_loss: {valid_loss:.3f} '  +\n",
    "                 f'valid_F1: {val_f1:.3f} '  +\n",
    "                 f'valid_AUC: {val_auc:.3f}')\n",
    "\n",
    "    print(print_msg)\n",
    "\n",
    "    # early_stopping needs the validation loss to check if it has decresed, \n",
    "    # and if it has, it will make a checkpoint of the current model\n",
    "    es([train_loss.data, val_auc], model)\n",
    "    if es.early_stop == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor(0.4700, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "params = []\n",
    "sum1 = 0\n",
    "print(model.n_clusters)\n",
    "for j in range(model.n_clusters):\n",
    "    prod = 1.0\n",
    "    for param in model.classifiers[j][0].parameters():\n",
    "        params.append(param.view(-1))\n",
    "        prod *= torch.norm(params[-1])\n",
    "    sum1 += B[j]*prod\n",
    "print(sum1/np.sqrt(args.n_clusters*len(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2, loss: 0.224, prod: 1.3558\n",
    "\n",
    "3, loss: 0.228, prod: 2.1169\n",
    "\n",
    "4, loss: 0.209, prod: 2.3198\n",
    "\n",
    "5, loss: 0.228, prod: 0.7546\n",
    "\n",
    "6, loss: 0.258, prod: 0.8493\n",
    "\n",
    "7, loss: 0.279, prod: 1.3236\n",
    "\n",
    "8, loss: 0.262, prod: 1.1561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2, loss: 1603.345, prod: 0.4700\n",
    "\n",
    "3, loss: 0.228, prod: 2.1169\n",
    "\n",
    "4, loss: 0.209, prod: 2.3198\n",
    "\n",
    "5, loss: 0.228, prod: 0.7546\n",
    "\n",
    "6, loss: 1747.416, prod: 1.4290\n",
    "\n",
    "7, loss: 0.279, prod: 1.3236\n",
    "\n",
    "8, loss: 1775.655, prod: 0.5288"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################\n",
      "\n",
      "Evaluating Test Data with k =  8  Attention =  True\n",
      "Loading Best model with score:  [tensor(0.2620), 0.845767032967033]\n",
      "Acc 0.0000 , nmi 0.0000 , ari 0.0000 , Test Loss 0.332, E-Test Loss 0.322\n",
      "Test F1 0.423, Test AUC 0.715, Test ACC 0.854 , E-Test F1 0.422, E-Test AUC 0.831, E-Test ACC 0.861\n",
      "0.35514018691588783 0.5187713310580204\n",
      "score1:  0.35514018691588783\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n####################################################################################\\n\")\n",
    "print(\"Evaluating Test Data with k = \", args.n_clusters, \" Attention = \", args.attention)\n",
    "\n",
    "# Load best model trained from local training phase\n",
    "model = es.load_checkpoint(model)\n",
    "model.ae.eval() # prep model for evaluation\n",
    "for j in range(model.n_clusters):\n",
    "    model.classifiers[j][0].eval()\n",
    "\n",
    "# # Evaluate model on Test dataset\n",
    "qs, z_test = model(torch.FloatTensor(X_test).to(args.device), output=\"latent\")\n",
    "q_test = qs[0]\n",
    "cluster_ids = torch.argmax(q_test, axis=1)\n",
    "preds_e = torch.zeros((len(z_test), 2))\n",
    "\n",
    "# Weighted predictions\n",
    "for j in range(model.n_clusters):\n",
    "    cluster_id = np.where(cluster_ids == j)[0]\n",
    "    # X_cluster = z_test[cluster_id]\n",
    "    X_cluster = z_test\n",
    "    cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "    # print(q_test, cluster_preds[:,0])\n",
    "    preds_e[:,0] += q_test[:,j]*cluster_preds[:,0]\n",
    "    preds_e[:,1] += q_test[:,j]*cluster_preds[:,1]\n",
    "\n",
    "e_test_f1 = f1_score(y_test, np.argmax(preds_e.detach().numpy(), axis=1))\n",
    "e_test_auc = roc_auc_score(y_test, preds_e[:,1].detach().numpy())\n",
    "e_test_acc = accuracy_score(y_test, np.argmax(preds_e.detach().numpy(), axis=1))\n",
    "e_test_loss = criterion(preds_e, torch.Tensor(y_test).type(torch.LongTensor))\n",
    "\n",
    "preds = torch.zeros((len(z_test), 2))\n",
    "\n",
    "# Hard local predictions\n",
    "for j in range(model.n_clusters):\n",
    "    cluster_id = np.where(cluster_ids == j)[0]\n",
    "    X_cluster = z_test[cluster_id]\n",
    "    cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "    preds[cluster_id,:] = cluster_preds\n",
    "\n",
    "test_f1 = f1_score(y_test, np.argmax(preds.detach().numpy(), axis=1))\n",
    "test_auc = roc_auc_score(y_test, preds[:,1].detach().numpy())\n",
    "test_acc = accuracy_score(y_test, np.argmax(preds.detach().numpy(), axis=1))\n",
    "test_loss = criterion(preds, torch.Tensor(y_test).type(torch.LongTensor))\n",
    "\n",
    "print('Acc {:.4f}'.format(acc),\n",
    "      ', nmi {:.4f}'.format(nmi), ', ari {:.4f}'.format(ari),\\\n",
    "      ', Test Loss {:.3f}, E-Test Loss {:.3f}'.format(test_loss, e_test_loss))\n",
    "\n",
    "print('Test F1 {:.3f}, Test AUC {:.3f}, Test ACC {:.3f}'.format(test_f1, test_auc, test_acc),\\\n",
    "    ', E-Test F1 {:.3f}, E-Test AUC {:.3f}, E-Test ACC {:.3f}'.format(e_test_f1, e_test_auc, e_test_acc))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, np.argmax(preds_e.detach().numpy(), axis=1)).ravel()\n",
    "se = tp/(tp+fn)\n",
    "pn = tp/(tp+fp)\n",
    "print(se, pn)\n",
    "print(\"score1: \", min(se, pn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(model, torch.FloatTensor(X_train).to(args.device), y_train, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3419,  2.1053, -0.6603,  ..., -0.4839, -0.1282,  0.0313],\n",
      "        [-0.0090,  2.0051, -0.5445,  ..., -0.0861,  0.2605,  0.1039],\n",
      "        [-0.3041,  1.4197, -0.3802,  ..., -0.2679,  0.3264, -0.3431],\n",
      "        ...,\n",
      "        [ 0.0938,  2.0480, -0.2896,  ..., -0.2714, -0.1084, -0.0495],\n",
      "        [ 0.2282,  2.2892, -0.5455,  ..., -0.4342,  0.1029, -0.1579],\n",
      "        [-0.1288,  1.0017, -0.2808,  ...,  0.1140,  0.2142, -0.1672]],\n",
      "       grad_fn=<AddmmBackward>) tensor([[0.3391, 0.5618, 0.0991],\n",
      "        [0.3746, 0.5259, 0.0995],\n",
      "        [0.3213, 0.4794, 0.1993],\n",
      "        ...,\n",
      "        [0.4483, 0.4203, 0.1314],\n",
      "        [0.2534, 0.6727, 0.0739],\n",
      "        [0.4310, 0.2258, 0.3432]], grad_fn=<TBackward>)\n",
      "[0 2 2 ... 2 0 1]\n",
      "0.6851140266630791\n"
     ]
    }
   ],
   "source": [
    "print(z_val, q_val)\n",
    "q_labels = torch.argmax(q_val, axis=1).data.cpu().numpy()\n",
    "km_labels = kmeans.fit_predict(z_val.data.cpu().numpy())\n",
    "print(km_labels)\n",
    "print(nmi_score(q_labels, km_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #  0 sized:  2200\n",
      "[('Age', 0.147), ('BUN_last', 0.146), ('GCS_last', 0.09), ('HCO3_last', 0.052), ('MechVentStartTime', 0.05), ('GCS_first', 0.049), ('CSRU', 0.041), ('Temp_median', 0.037), ('Glucose_last', 0.029), ('FiO2_last', 0.02)]\n",
      "=========================\n",
      "\n",
      "Cluster #  1 sized:  2194\n",
      "[('MechVentStartTime', 0.186), ('Age', 0.115), ('GCS_last', 0.07), ('BUN_first', 0.064), ('Temp_median', 0.055), ('GCS_first', 0.051), ('MechVentLast8Hour', 0.031), ('PaO2_first', 0.03), ('BUN_last', 0.029), ('Glucose_last', 0.022)]\n",
      "=========================\n",
      "\n",
      "Cluster #  2 sized:  2356\n",
      "[('GCS_last', 0.236), ('Age', 0.089), ('HCO3_last', 0.071), ('Lactate_last', 0.07), ('Bilirubin_last', 0.063), ('Length_of_stay', 0.057), ('BUN_last', 0.045), ('GCS_highest', 0.039), ('BUN_first', 0.037), ('ALP_last', 0.027)]\n",
      "=========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "################################### Feature Imp. ###################################\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "\n",
    "plot(model, torch.FloatTensor(X_train).to(args.device), y_train, labels=None)\n",
    "\n",
    "regs = [GradientBoostingRegressor(random_state=0) for _ in range(args.n_clusters)]\n",
    "qs, z_train = model(torch.FloatTensor(X_train).to(args.device), output=\"latent\")\n",
    "q_train = qs[0]\n",
    "cluster_ids = torch.argmax(q_train, axis=1)\n",
    "preds_e = torch.zeros((len(z_train), 2))\n",
    "feature_importances = np.zeros((args.n_clusters, args.input_dim))\n",
    "\n",
    "# Weighted predictions\n",
    "for j in range(model.n_clusters):\n",
    "    cluster_id = np.where(cluster_ids == j)[0]\n",
    "    # X_cluster = z_test[cluster_id]\n",
    "    X_cluster = z_train\n",
    "    cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "    # print(q_test, cluster_preds[:,0])\n",
    "    preds_e[:,0] += q_train[:,j]*cluster_preds[:,0]\n",
    "    preds_e[:,1] += q_train[:,j]*cluster_preds[:,1]\n",
    "\n",
    "for j in range(model.n_clusters):\n",
    "    cluster_id = torch.where(cluster_ids == j)[0]\n",
    "    X_cluster = X_train[cluster_id]\n",
    "    if args.attention == True:\n",
    "        y_cluster = preds_e[cluster_id][:,1]\n",
    "    else:\n",
    "        y_cluster = preds[cluster_id][:,1]\n",
    "\n",
    "    # Some test data might not belong to any cluster\n",
    "    if len(cluster_id) > 0:\n",
    "        regs[j].fit(X_cluster, y_cluster.detach().cpu().numpy())\n",
    "        best_features = np.argsort(regs[j].feature_importances_)[::-1][:10]\n",
    "        feature_importances[j,:] = regs[j].feature_importances_\n",
    "        print(\"Cluster # \", j, \"sized: \", len(cluster_id))\n",
    "        print(list(zip(column_names[best_features], np.round(regs[j].feature_importances_[best_features], 3))))\n",
    "        print(\"=========================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.01984 |  Train F1: 0.000 | Train Acc: 0.018|  Val F1: 0.000 | Val Acc: 0.559 | Val Loss: 0.564\n",
      "Epoch 002: | Train Loss: 0.01951 |  Train F1: 0.000 | Train Acc: 0.019|  Val F1: 0.000 | Val Acc: 0.588 | Val Loss: 0.554\n",
      "Epoch 003: | Train Loss: 0.01918 |  Train F1: 0.000 | Train Acc: 0.020|  Val F1: 0.000 | Val Acc: 0.602 | Val Loss: 0.544\n",
      "Epoch 004: | Train Loss: 0.01884 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.612 | Val Loss: 0.534\n",
      "Epoch 005: | Train Loss: 0.01849 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.614 | Val Loss: 0.524\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 006: | Train Loss: 0.01813 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.612 | Val Loss: 0.512\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 007: | Train Loss: 0.01776 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.609 | Val Loss: 0.500\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 008: | Train Loss: 0.01735 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.610 | Val Loss: 0.488\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 009: | Train Loss: 0.01691 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.611 | Val Loss: 0.474\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 010: | Train Loss: 0.01645 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.614 | Val Loss: 0.459\n",
      "Epoch 011: | Train Loss: 0.01596 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.615 | Val Loss: 0.444\n",
      "Epoch 012: | Train Loss: 0.01546 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.615 | Val Loss: 0.429\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 013: | Train Loss: 0.01494 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.615 | Val Loss: 0.414\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 014: | Train Loss: 0.01443 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.614 | Val Loss: 0.399\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 015: | Train Loss: 0.01391 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.613 | Val Loss: 0.384\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 016: | Train Loss: 0.01341 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.611 | Val Loss: 0.369\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 017: | Train Loss: 0.01292 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.609 | Val Loss: 0.355\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 018: | Train Loss: 0.01244 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.607 | Val Loss: 0.341\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Epoch 019: | Train Loss: 0.01199 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.605 | Val Loss: 0.329\n",
      "\n",
      "####################################################################################\n",
      "\n",
      "Evaluating Test Data\n",
      "Loading Best model with score:  [0.0, 0.6154440394857437]\n",
      "Epoch 019: | Train Loss: 0.01199 |  Train F1: 0.000 | Train Acc: 0.021|  Test F1: 0.000 | Test Acc: 0.605 | Test Loss: 0.433\n",
      "Epoch 001: | Train Loss: 0.01670 |  Train F1: 0.000 | Train Acc: 0.013|  Val F1: 0.000 | Val Acc: 0.379 | Val Loss: 0.474\n",
      "Epoch 002: | Train Loss: 0.01646 |  Train F1: 0.000 | Train Acc: 0.014|  Val F1: 0.000 | Val Acc: 0.402 | Val Loss: 0.469\n",
      "Epoch 003: | Train Loss: 0.01630 |  Train F1: 0.000 | Train Acc: 0.014|  Val F1: 0.000 | Val Acc: 0.423 | Val Loss: 0.465\n",
      "Epoch 004: | Train Loss: 0.01614 |  Train F1: 0.000 | Train Acc: 0.015|  Val F1: 0.000 | Val Acc: 0.442 | Val Loss: 0.459\n",
      "Epoch 005: | Train Loss: 0.01595 |  Train F1: 0.000 | Train Acc: 0.016|  Val F1: 0.000 | Val Acc: 0.458 | Val Loss: 0.453\n",
      "Epoch 006: | Train Loss: 0.01575 |  Train F1: 0.000 | Train Acc: 0.017|  Val F1: 0.000 | Val Acc: 0.473 | Val Loss: 0.447\n",
      "Epoch 007: | Train Loss: 0.01554 |  Train F1: 0.000 | Train Acc: 0.018|  Val F1: 0.000 | Val Acc: 0.486 | Val Loss: 0.440\n",
      "Epoch 008: | Train Loss: 0.01531 |  Train F1: 0.000 | Train Acc: 0.018|  Val F1: 0.000 | Val Acc: 0.499 | Val Loss: 0.433\n",
      "Epoch 009: | Train Loss: 0.01506 |  Train F1: 0.000 | Train Acc: 0.019|  Val F1: 0.000 | Val Acc: 0.516 | Val Loss: 0.425\n",
      "Epoch 010: | Train Loss: 0.01478 |  Train F1: 0.000 | Train Acc: 0.019|  Val F1: 0.000 | Val Acc: 0.526 | Val Loss: 0.416\n",
      "Epoch 011: | Train Loss: 0.01448 |  Train F1: 0.000 | Train Acc: 0.019|  Val F1: 0.000 | Val Acc: 0.535 | Val Loss: 0.406\n",
      "Epoch 012: | Train Loss: 0.01415 |  Train F1: 0.000 | Train Acc: 0.019|  Val F1: 0.000 | Val Acc: 0.544 | Val Loss: 0.396\n",
      "Epoch 013: | Train Loss: 0.01382 |  Train F1: 0.000 | Train Acc: 0.020|  Val F1: 0.000 | Val Acc: 0.551 | Val Loss: 0.386\n",
      "Epoch 014: | Train Loss: 0.01348 |  Train F1: 0.000 | Train Acc: 0.020|  Val F1: 0.000 | Val Acc: 0.559 | Val Loss: 0.376\n",
      "Epoch 015: | Train Loss: 0.01313 |  Train F1: 0.000 | Train Acc: 0.020|  Val F1: 0.000 | Val Acc: 0.566 | Val Loss: 0.365\n",
      "Epoch 016: | Train Loss: 0.01279 |  Train F1: 0.000 | Train Acc: 0.020|  Val F1: 0.000 | Val Acc: 0.573 | Val Loss: 0.355\n",
      "Epoch 017: | Train Loss: 0.01244 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.578 | Val Loss: 0.345\n",
      "Epoch 018: | Train Loss: 0.01211 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.581 | Val Loss: 0.335\n",
      "Epoch 019: | Train Loss: 0.01178 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.582 | Val Loss: 0.326\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 020: | Train Loss: 0.01146 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.582 | Val Loss: 0.316\n",
      "Epoch 021: | Train Loss: 0.01116 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.583 | Val Loss: 0.308\n",
      "Epoch 022: | Train Loss: 0.01087 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.584 | Val Loss: 0.300\n",
      "Epoch 023: | Train Loss: 0.01061 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.585 | Val Loss: 0.292\n",
      "Epoch 024: | Train Loss: 0.01037 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.586 | Val Loss: 0.285\n",
      "Epoch 025: | Train Loss: 0.01014 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.587 | Val Loss: 0.279\n",
      "Epoch 026: | Train Loss: 0.00995 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.588 | Val Loss: 0.274\n",
      "Epoch 027: | Train Loss: 0.00978 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.589 | Val Loss: 0.269\n",
      "Epoch 028: | Train Loss: 0.00964 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.590 | Val Loss: 0.266\n",
      "Epoch 029: | Train Loss: 0.00952 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.590 | Val Loss: 0.263\n",
      "Epoch 030: | Train Loss: 0.00943 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.591 | Val Loss: 0.260\n",
      "Epoch 031: | Train Loss: 0.00937 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.592 | Val Loss: 0.259\n",
      "Epoch 032: | Train Loss: 0.00933 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.593 | Val Loss: 0.258\n",
      "Epoch 033: | Train Loss: 0.00930 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.594 | Val Loss: 0.257\n",
      "Epoch 034: | Train Loss: 0.00930 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.595 | Val Loss: 0.257\n",
      "Epoch 035: | Train Loss: 0.00930 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.596 | Val Loss: 0.257\n",
      "Epoch 036: | Train Loss: 0.00932 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.597 | Val Loss: 0.257\n",
      "Epoch 037: | Train Loss: 0.00934 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.598 | Val Loss: 0.258\n",
      "Epoch 038: | Train Loss: 0.00936 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.599 | Val Loss: 0.258\n",
      "Epoch 039: | Train Loss: 0.00938 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.600 | Val Loss: 0.259\n",
      "Epoch 040: | Train Loss: 0.00940 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.601 | Val Loss: 0.259\n",
      "Epoch 041: | Train Loss: 0.00941 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.603 | Val Loss: 0.259\n",
      "Epoch 042: | Train Loss: 0.00942 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.604 | Val Loss: 0.259\n",
      "Epoch 043: | Train Loss: 0.00942 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.605 | Val Loss: 0.259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 044: | Train Loss: 0.00942 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.606 | Val Loss: 0.259\n",
      "Epoch 045: | Train Loss: 0.00941 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.608 | Val Loss: 0.259\n",
      "Epoch 046: | Train Loss: 0.00940 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.609 | Val Loss: 0.258\n",
      "Epoch 047: | Train Loss: 0.00938 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.610 | Val Loss: 0.258\n",
      "Epoch 048: | Train Loss: 0.00936 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.612 | Val Loss: 0.257\n",
      "Epoch 049: | Train Loss: 0.00934 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.614 | Val Loss: 0.257\n",
      "\n",
      "####################################################################################\n",
      "\n",
      "Evaluating Test Data\n",
      "Loading Best model with score:  [0.0, 0.6135114589475008]\n",
      "Epoch 049: | Train Loss: 0.00934 |  Train F1: 0.000 | Train Acc: 0.022|  Test F1: 0.000 | Test Acc: 0.600 | Test Loss: 0.258\n",
      "Epoch 001: | Train Loss: 0.02699 |  Train F1: 0.005 | Train Acc: 0.018|  Val F1: 0.135 | Val Acc: 0.572 | Val Loss: 0.774\n",
      "Epoch 002: | Train Loss: 0.02665 |  Train F1: 0.005 | Train Acc: 0.018|  Val F1: 0.135 | Val Acc: 0.577 | Val Loss: 0.765\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 003: | Train Loss: 0.02635 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.574 | Val Loss: 0.757\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 004: | Train Loss: 0.02608 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.564 | Val Loss: 0.750\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 005: | Train Loss: 0.02583 |  Train F1: 0.005 | Train Acc: 0.018|  Val F1: 0.135 | Val Acc: 0.549 | Val Loss: 0.744\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 006: | Train Loss: 0.02562 |  Train F1: 0.005 | Train Acc: 0.017|  Val F1: 0.135 | Val Acc: 0.525 | Val Loss: 0.739\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 007: | Train Loss: 0.02546 |  Train F1: 0.005 | Train Acc: 0.016|  Val F1: 0.135 | Val Acc: 0.505 | Val Loss: 0.735\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 008: | Train Loss: 0.02531 |  Train F1: 0.005 | Train Acc: 0.016|  Val F1: 0.135 | Val Acc: 0.502 | Val Loss: 0.730\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Epoch 009: | Train Loss: 0.02515 |  Train F1: 0.005 | Train Acc: 0.016|  Val F1: 0.135 | Val Acc: 0.513 | Val Loss: 0.725\n",
      "\n",
      "####################################################################################\n",
      "\n",
      "Evaluating Test Data\n",
      "Loading Best model with score:  [0.13509830640451626, 0.577060959797525]\n",
      "Epoch 009: | Train Loss: 0.02515 |  Train F1: 0.005 | Train Acc: 0.016|  Test F1: 0.135 | Test Acc: 0.580 | Test Loss: 0.768\n",
      "Epoch 001: | Train Loss: 0.03135 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.511 | Val Loss: 0.893\n",
      "Epoch 002: | Train Loss: 0.03071 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.511 | Val Loss: 0.874\n",
      "Epoch 003: | Train Loss: 0.03007 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.513 | Val Loss: 0.854\n",
      "Epoch 004: | Train Loss: 0.02938 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.522 | Val Loss: 0.833\n",
      "Epoch 005: | Train Loss: 0.02866 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.530 | Val Loss: 0.811\n",
      "Epoch 006: | Train Loss: 0.02792 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.538 | Val Loss: 0.788\n",
      "Epoch 007: | Train Loss: 0.02715 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.546 | Val Loss: 0.766\n",
      "Epoch 008: | Train Loss: 0.02637 |  Train F1: 0.005 | Train Acc: 0.019|  Val F1: 0.135 | Val Acc: 0.554 | Val Loss: 0.742\n",
      "Epoch 009: | Train Loss: 0.02556 |  Train F1: 0.005 | Train Acc: 0.020|  Val F1: 0.134 | Val Acc: 0.563 | Val Loss: 0.718\n",
      "Epoch 010: | Train Loss: 0.02474 |  Train F1: 0.005 | Train Acc: 0.020|  Val F1: 0.146 | Val Acc: 0.572 | Val Loss: 0.693\n",
      "Epoch 011: | Train Loss: 0.02390 |  Train F1: 0.006 | Train Acc: 0.020|  Val F1: 0.165 | Val Acc: 0.579 | Val Loss: 0.667\n",
      "Epoch 012: | Train Loss: 0.02302 |  Train F1: 0.007 | Train Acc: 0.020|  Val F1: 0.011 | Val Acc: 0.585 | Val Loss: 0.641\n",
      "Epoch 013: | Train Loss: 0.02213 |  Train F1: 0.001 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.588 | Val Loss: 0.615\n",
      "Epoch 014: | Train Loss: 0.02123 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.588 | Val Loss: 0.588\n",
      "Epoch 015: | Train Loss: 0.02033 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.589 | Val Loss: 0.562\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 016: | Train Loss: 0.01943 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.589 | Val Loss: 0.536\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 017: | Train Loss: 0.01854 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.588 | Val Loss: 0.510\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 018: | Train Loss: 0.01767 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.587 | Val Loss: 0.485\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 019: | Train Loss: 0.01682 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.587 | Val Loss: 0.460\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 020: | Train Loss: 0.01599 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.587 | Val Loss: 0.437\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 021: | Train Loss: 0.01519 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.586 | Val Loss: 0.414\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Epoch 022: | Train Loss: 0.01443 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.586 | Val Loss: 0.393\n",
      "\n",
      "####################################################################################\n",
      "\n",
      "Evaluating Test Data\n",
      "Loading Best model with score:  [0.0, 0.5887391428150748]\n",
      "Epoch 022: | Train Loss: 0.01443 |  Train F1: 0.000 | Train Acc: 0.021|  Test F1: 0.000 | Test Acc: 0.562 | Test Loss: 0.522\n",
      "Epoch 001: | Train Loss: 0.02201 |  Train F1: 0.000 | Train Acc: 0.014|  Val F1: 0.000 | Val Acc: 0.460 | Val Loss: 0.624\n",
      "Epoch 002: | Train Loss: 0.02154 |  Train F1: 0.000 | Train Acc: 0.016|  Val F1: 0.000 | Val Acc: 0.511 | Val Loss: 0.611\n",
      "Epoch 003: | Train Loss: 0.02111 |  Train F1: 0.000 | Train Acc: 0.018|  Val F1: 0.000 | Val Acc: 0.564 | Val Loss: 0.599\n",
      "Epoch 004: | Train Loss: 0.02069 |  Train F1: 0.000 | Train Acc: 0.020|  Val F1: 0.000 | Val Acc: 0.591 | Val Loss: 0.588\n",
      "Epoch 005: | Train Loss: 0.02031 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.605 | Val Loss: 0.576\n",
      "Epoch 006: | Train Loss: 0.01993 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.610 | Val Loss: 0.565\n",
      "Epoch 007: | Train Loss: 0.01953 |  Train F1: 0.000 | Train Acc: 0.021|  Val F1: 0.000 | Val Acc: 0.617 | Val Loss: 0.553\n",
      "Epoch 008: | Train Loss: 0.01912 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.626 | Val Loss: 0.540\n",
      "Epoch 009: | Train Loss: 0.01868 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.631 | Val Loss: 0.527\n",
      "Epoch 010: | Train Loss: 0.01823 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.635 | Val Loss: 0.513\n",
      "Epoch 011: | Train Loss: 0.01778 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.640 | Val Loss: 0.500\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 012: | Train Loss: 0.01733 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.639 | Val Loss: 0.487\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 013: | Train Loss: 0.01689 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.637 | Val Loss: 0.474\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 014: | Train Loss: 0.01644 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.635 | Val Loss: 0.461\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 015: | Train Loss: 0.01599 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.633 | Val Loss: 0.447\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 016: | Train Loss: 0.01554 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.631 | Val Loss: 0.434\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 017: | Train Loss: 0.01508 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.630 | Val Loss: 0.420\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Epoch 018: | Train Loss: 0.01463 |  Train F1: 0.000 | Train Acc: 0.022|  Val F1: 0.000 | Val Acc: 0.628 | Val Loss: 0.407\n",
      "\n",
      "####################################################################################\n",
      "\n",
      "Evaluating Test Data\n",
      "Loading Best model with score:  [0.0, 0.6395301095334369]\n",
      "Epoch 018: | Train Loss: 0.01463 |  Train F1: 0.000 | Train Acc: 0.022|  Test F1: 0.000 | Test Acc: 0.642 | Test Loss: 0.495\n",
      "[0.0, 0.0, 0.13494517852122576, 0.0, 0.0] [0.6047895677608061, 0.5999607301484129, 0.5803474704799046, 0.5616712707182321, 0.6420850937059908]\n",
      "Avg. Test F1 = 0.027, AUC = 0.598\n"
     ]
    }
   ],
   "source": [
    "f1_scores, auc_scores = [], []\n",
    "\n",
    "for r in range(5):\n",
    "    m = NNClassifier(args, input_dim=89)\n",
    "    device = args.device\n",
    "\n",
    "    N_EPOCHS = args.n_epochs\n",
    "    es = EarlyStopping(dataset=args.dataset, path=\"./pretrained_model/checkpoint_base\")\n",
    "\n",
    "    kmeans = KMeans(n_clusters=args.n_classes, n_init=20)\n",
    "\n",
    "    for e in range(1, N_EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        epoch_f1 = 0\n",
    "        m.train()\n",
    "        nmi, acc, ari = 0, 0, 0\n",
    "\n",
    "#         for X_batch, y_batch, _ in train_loader:\n",
    "        X_batch, y_batch = torch.FloatTensor(X_train), torch.Tensor(y_train).type(torch.LongTensor)\n",
    "        y_pred, train_loss = m.fit(X_batch, y_batch)\n",
    "        epoch_loss += train_loss\n",
    "\n",
    "        f1 = f1_score(np.argmax(y_pred, axis=1), y_batch)\n",
    "        acc = roc_auc_score(y_batch, y_pred[:,1])\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_f1 += f1.item()\n",
    "\n",
    "\n",
    "        m.classifier.eval()\n",
    "        val_pred = m(torch.FloatTensor(X_val).to(args.device))\n",
    "        val_loss = nn.CrossEntropyLoss(reduction='mean')(val_pred, torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "        val_f1 = f1_score(torch.argmax(val_pred, axis=1), y_val)\n",
    "        val_auc = roc_auc_score(y_val, val_pred[:,1].data.cpu().numpy())\n",
    "        es([val_f1, val_auc], m)\n",
    "\n",
    "        print(f'Epoch {e+0:03}: | Train Loss: {epoch_loss/len(train_loader):.5f} | ',\n",
    "            f'Train F1: {epoch_f1/len(train_loader):.3f} | Train Acc: {epoch_acc/len(train_loader):.3f}| ',\n",
    "            f'Val F1: {val_f1:.3f} | Val Acc: {val_auc:.3f} | Val Loss: {val_loss:.3f}')\n",
    "\n",
    "        if es.early_stop == True:\n",
    "            break\n",
    "\n",
    "\n",
    "    ###################################### Testing #####################################\n",
    "\n",
    "    print(\"\\n####################################################################################\\n\")\n",
    "    print(\"Evaluating Test Data\")\n",
    "\n",
    "    # Load best model trained from local training phase\n",
    "    m = es.load_checkpoint(m)\n",
    "    m.classifier.eval()\n",
    "    test_pred = m.classifier(torch.FloatTensor(X_test))\n",
    "    test_loss = nn.CrossEntropyLoss(reduction='mean')(test_pred, torch.Tensor(y_test).type(torch.LongTensor))\n",
    "\n",
    "    test_f1 = f1_score(np.argmax(test_pred.detach().numpy(), axis=1), y_test)\n",
    "    test_auc = roc_auc_score(y_test, test_pred[:,1].detach().numpy())\n",
    "    f1_scores.append(test_f1)\n",
    "    auc_scores.append(test_auc)\n",
    "    \n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {epoch_loss/len(train_loader):.5f} | ',\n",
    "        f'Train F1: {epoch_f1/len(train_loader):.3f} | Train Acc: {epoch_acc/len(train_loader):.3f}| ',\n",
    "        f'Test F1: {test_f1:.3f} | Test Acc: {test_auc:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "\n",
    "#     reg = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "#     reg.fit(X_test, y_test)\n",
    "#     best_features = np.argsort(reg.feature_importances_)[::-1][:10]\n",
    "#     print(\"Best Features \")\n",
    "#     print(column_names[best_features])\n",
    "#     print(\"=========================\\n\")\n",
    "print(f1_scores, auc_scores)\n",
    "print(\"Avg. Test F1 = {:.3f}, AUC = {:.3f}\".format(np.average(f1_scores), np.average(auc_scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
