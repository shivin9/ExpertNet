{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import copy\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import umap\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score,\\\n",
    "f1_score, roc_auc_score, roc_curve, accuracy_score, matthews_corrcoef as mcc\n",
    "from torch.utils.data import Subset\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import Linear\n",
    "from pytorchtools import EarlyStoppingCAC\n",
    "\n",
    "import numbers\n",
    "from sklearn.metrics import davies_bouldin_score as dbs, adjusted_rand_score as ari,\\\n",
    "silhouette_score, mutual_info_score\n",
    "from matplotlib import pyplot as plt\n",
    "color = ['grey', 'red', 'blue', 'pink', 'brown', 'black', 'magenta', 'purple', 'orange', 'cyan', 'olive']\n",
    "\n",
    "from models import MultiHeadIDEC,  target_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     127,
     157,
     222,
     270,
     336,
     365
    ]
   },
   "outputs": [],
   "source": [
    "## Utils.py\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from scipy.stats import ttest_ind\n",
    "from read_patients import get_aki\n",
    "import sys\n",
    "\n",
    "color = ['grey', 'red', 'blue', 'pink', 'brown', 'black', 'magenta', 'purple', 'orange', 'cyan', 'olive']\n",
    "DATASETS = ['diabetes', 'ards', 'cic', 'sepsis', 'aki', 'infant', 'wid_mortality', 'synthetic']\n",
    "\n",
    "DATA_DIR = \"/Users/shivin/Document/NUS/Research/Data\"\n",
    "BASE_DIR = \"/Users/shivin/Document/NUS/Research/cac/cac_dl/DeepCAC\"\n",
    "\n",
    "# Disable Print\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "\n",
    "# Restore Print\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "\n",
    "def calculate_bound(model, B, m):\n",
    "    sum1 = 0\n",
    "    for j in range(model.n_clusters):\n",
    "        prod = 1.0\n",
    "        for param in model.classifiers[j][0].parameters():\n",
    "            prod *= torch.norm(param.view(-1))\n",
    "        sum1 += B[j]*prod\n",
    "    x = sum1/np.sqrt(model.n_clusters*m)\n",
    "    return x.item()\n",
    "\n",
    "\n",
    "def silhouette_new(X, labels, metric=\"euclidean\"):\n",
    "    if len(np.unique(labels)) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return silhouette_score(X, labels, metric=metric)\n",
    "\n",
    "\n",
    "def calculate_nhfd(X, cluster_ids):\n",
    "    feature_diff = 0\n",
    "    cntr = 0\n",
    "    n_clusters = len(torch.unique(cluster_ids))\n",
    "    n_columns = X.shape[1]\n",
    "    top_quartile = np.int(n_columns/4)\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(n_clusters):\n",
    "            if i > j:\n",
    "                ci = torch.where(cluster_ids == i)[0]\n",
    "                cj = torch.where(cluster_ids == j)[0]\n",
    "                Xi = X[ci]\n",
    "                Xj = X[cj]\n",
    "                # feature_diff += sum(ttest_ind(Xi, Xj, axis=0)[1] < 0.05)/n_columns\n",
    "                # Take the max element and take negative exp weighted by 0.05, top 5 features\n",
    "                col_p_val = np.sort(np.nan_to_num(ttest_ind(Xi, Xj, axis=0)[1]))[::-1]\n",
    "                feature_diff += np.sum(np.exp(-col_p_val[:top_quartile]/0.05))/top_quartile\n",
    "                # feature_diff += torch.nn.functional.kl_div(Xi.log(), Xj, reduction='batchmean')\n",
    "                cntr += 1\n",
    "    if cntr == 0:\n",
    "        return 0\n",
    "    return feature_diff/cntr\n",
    "\n",
    "\n",
    "def shannon_entropy(A, mode=\"auto\", verbose=False):\n",
    "     \"\"\"\n",
    "     https://stackoverflow.com/questions/42683287/python-numpy-shannon-entropy-array\n",
    "     \"\"\"\n",
    "     A = np.asarray(A)\n",
    " \n",
    "     # Determine distribution type\n",
    "     if mode == \"auto\":\n",
    "         condition = np.all(A.astype(float) == A.astype(int))\n",
    "         if condition:\n",
    "             mode = \"discrete\"\n",
    "         else:\n",
    "             mode = \"continuous\"\n",
    "     if verbose:\n",
    "         print(mode, file=sys.stderr)\n",
    "     # Compute shannon entropy\n",
    "     pA = A / A.sum()\n",
    "     # Remove zeros\n",
    "     pA = pA[np.nonzero(pA)[0]]\n",
    "     if mode == \"continuous\":\n",
    "         return -np.sum(pA*np.log2(A))\n",
    "     if mode == \"discrete\":\n",
    "         return -np.sum(pA*np.log2(pA))\n",
    "\n",
    "\n",
    "def calc_MI(x, y, c, bins=10):\n",
    "    minn = min(np.min(x), np.min(y))\n",
    "    maxx = max(np.max(x), np.max(y))\n",
    "    range_x = np.max(x) - np.min(x)\n",
    "    range_y = np.max(y) - np.min(y)\n",
    "    gap = min(range_x, range_y)/bins\n",
    "\n",
    "    if gap < 1e-5:\n",
    "        return 0\n",
    "\n",
    "    h1 = np.histogram(x, np.arange(minn-gap, maxx+gap, gap))[0]\n",
    "    h2 = np.histogram(y, np.arange(minn-gap, maxx+gap, gap))[0]\n",
    "    c_xy = np.histogram2d(h1, h2, bins)[0]\n",
    "\n",
    "    if np.sum(c_xy) == 0:\n",
    "        return 0\n",
    "\n",
    "    h_x = shannon_entropy(h1)\n",
    "    h_y = shannon_entropy(h2)\n",
    "    if h_x * h_y == 0:\n",
    "        # print(\"Column: \", c, x, y)\n",
    "        # print(h1, h2, range_x, range_y, mutual_info_score(None, None, contingency=c_xy))\n",
    "        return 0\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)/np.sqrt(h_x * h_y)\n",
    "    return mi\n",
    "\n",
    "\n",
    "def calculate_MIFD(X, cluster_ids):\n",
    "    cluster_entrpy = 0\n",
    "    cntr = 0\n",
    "    n_columns = X.shape[1]\n",
    "    n_clusters = len(torch.unique(cluster_ids))\n",
    "    top_quartile = np.int(n_columns/4)\n",
    "    col_entrpy = np.zeros(n_columns)\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(n_clusters):\n",
    "            if i > j:\n",
    "                col_entrpy *= 0\n",
    "                ci = torch.where(cluster_ids == i)[0]\n",
    "                cj = torch.where(cluster_ids == j)[0]\n",
    "                Xi = X[ci]\n",
    "                Xj = X[cj]\n",
    "                for c in range(n_columns):\n",
    "                    col_entrpy[c] = calc_MI(Xi[:,c], Xj[:,c], c)\n",
    "                # Sort col_entrpy\n",
    "                col_entrpy = np.sort(col_entrpy)[::-1]\n",
    "                cluster_entrpy += np.sum(col_entrpy[:top_quartile])/top_quartile\n",
    "                cntr += 1\n",
    "    if cntr == 0:\n",
    "        return 0\n",
    "    return cluster_entrpy/cntr\n",
    "\n",
    "\n",
    "def is_non_zero_file(fpath):\n",
    "    return os.path.isfile(fpath) and os.path.getsize(fpath) > 0\n",
    "\n",
    "\n",
    "class parameters(object):\n",
    "    def __init__(self, parser):\n",
    "        self.input_dim = -1\n",
    "        self.dataset = parser.dataset\n",
    "        \n",
    "        # Training parameters\n",
    "        self.lr = parser.lr\n",
    "        self.alpha = float(parser.alpha)\n",
    "        self.wd = parser.wd\n",
    "        self.batch_size = parser.batch_size\n",
    "        self.n_epochs = parser.n_epochs\n",
    "        self.pre_epoch = parser.pre_epoch\n",
    "        self.pretrain = parser.pretrain\n",
    "        self.load_ae = parser.load_ae\n",
    "        self.classifier = parser.classifier\n",
    "        self.tol = parser.tol\n",
    "        self.attention = parser.attention == \"True\"\n",
    "        self.ablation = parser.ablation\n",
    "        self.cluster_balance = parser.cluster_balance\n",
    "\n",
    "        # Model parameters\n",
    "        self.lamda = parser.lamda\n",
    "        self.beta = parser.beta\n",
    "        self.gamma = parser.gamma\n",
    "        self.delta = parser.delta\n",
    "        self.eta = parser.eta\n",
    "        self.hidden_dims = parser.hidden_dims\n",
    "        self.latent_dim = self.n_z = parser.n_z\n",
    "        self.n_clusters = parser.n_clusters\n",
    "        self.clustering = parser.clustering\n",
    "        self.n_classes = parser.n_classes\n",
    "\n",
    "        # Utility parameters\n",
    "        self.device = parser.device\n",
    "        self.verbose = parser.verbose\n",
    "        self.log_interval = parser.log_interval\n",
    "        self.pretrain_path = parser.pretrain_path + \"/\" + self.dataset + \".pth\"\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Evaluate Critiron\n",
    "#######################################################\n",
    "\n",
    "\n",
    "def cluster_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    row, col = linear_assignment(w.max() - w)\n",
    "    return sum([w[i, j] for i, j in zip(row, col)]) * 1.0 / y_pred.size\n",
    "\n",
    "\n",
    "def plot(model, X_train, y_train, X_test=None, y_test=None, labels=None):\n",
    "    reducer = umap.UMAP(random_state=42)\n",
    "    # idx = torch.Tensor(np.random.randint(0,len(X_train), int(0.1*len(X_train)))).type(torch.LongTensor).to(device)\n",
    "    idx = range(int(0.2*len(X_train)))\n",
    "    qs, latents_X = model(X_train[idx], output=\"latent\")\n",
    "    q_train = qs[0]\n",
    "    y_train = y_train[idx]\n",
    "\n",
    "    if labels is not None:\n",
    "        cluster_id_train = labels[idx]\n",
    "    else:\n",
    "        cluster_id_train = torch.argmax(q_train, axis=1)\n",
    "\n",
    "    X2 = reducer.fit_transform(latents_X.cpu().detach().numpy())\n",
    "\n",
    "    print(\"Training data\")\n",
    "\n",
    "    c_clusters = [color[int(cluster_id_train[i])] for i in range(len(cluster_id_train))]\n",
    "    c_labels = [color[int(y_train[i])] for i in range(len(cluster_id_train))]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('Clusters vs Labels')\n",
    "    ax1.scatter(X2[:,0], X2[:,1], color=c_clusters)\n",
    "    ax2.scatter(X2[:,0], X2[:,1], color=c_labels)\n",
    "    plt.show()\n",
    "    if X_test is not None:\n",
    "        qs, latents_test = model(X_test, output=\"latent\")\n",
    "        q_test = qs[0]\n",
    "        X2 = reducer.transform(latents_test.cpu().detach().numpy())\n",
    "        cluster_id_test = torch.argmax(q_test, axis=1)\n",
    "        c_clusters = [color[int(cluster_id_test[i])] for i in range(len(cluster_id_test))]\n",
    "        c_labels = [color[int(y_test[i])] for i in range(len(cluster_id_test))]\n",
    "\n",
    "        print(\"Test data\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.suptitle('Clusters vs Labels')\n",
    "        ax1.scatter(X2[:,0], X2[:,1], color=c_clusters)\n",
    "        ax2.scatter(X2[:,0], X2[:,1], color=c_labels)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def drop_constant_column(dataframe):\n",
    "    \"\"\"\n",
    "    Drops constant value columns of pandas dataframe.\n",
    "    \"\"\"\n",
    "    return dataframe.loc[:, (dataframe != dataframe.iloc[0]).any()]\n",
    "\n",
    "\n",
    "def get_dataset(DATASET, DATA_DIR):\n",
    "    if DATASET == \"cic\":\n",
    "        Xa = pd.read_csv(DATA_DIR + \"/CIC/cic_set_a.csv\")\n",
    "        Xb = pd.read_csv(DATA_DIR + \"/CIC/cic_set_b.csv\")\n",
    "        Xc = pd.read_csv(DATA_DIR + \"/CIC/cic_set_c.csv\")\n",
    "\n",
    "        ya = Xa['In-hospital_death']\n",
    "        yb = Xb['In-hospital_death']\n",
    "        yc = Xc['In-hospital_death']\n",
    "\n",
    "        Xa = Xa.drop(columns=['recordid', 'Survival', 'In-hospital_death'])\n",
    "        Xb = Xb.drop(columns=['recordid', 'Survival', 'In-hospital_death'])\n",
    "        Xc = Xc.drop(columns=['recordid', 'Survival', 'In-hospital_death'])\n",
    "\n",
    "        cols = Xa.columns\n",
    "\n",
    "        scale = StandardScaler()\n",
    "        Xa = scale.fit_transform(Xa)\n",
    "        Xb = scale.transform(Xb)\n",
    "        Xc = scale.transform(Xc)\n",
    "\n",
    "        Xa = pd.DataFrame(Xa, columns=cols)\n",
    "        Xb = pd.DataFrame(Xb, columns=cols)\n",
    "        Xc = pd.DataFrame(Xc, columns=cols)\n",
    "\n",
    "        Xa = Xa.fillna(0)\n",
    "        Xb = Xb.fillna(0)\n",
    "        Xc = Xc.fillna(0)\n",
    "\n",
    "        X_train = pd.concat([Xa, Xb])\n",
    "        y_train = pd.concat([ya, yb])\n",
    "\n",
    "        X_test = Xc\n",
    "        y_test = yc\n",
    "\n",
    "        X = pd.concat([X_train, X_test])\n",
    "        y = pd.concat([y_train, y_test]).to_numpy()\n",
    "        columns = cols\n",
    "\n",
    "    elif DATASET == \"infant\":\n",
    "        X = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"X.csv\")\n",
    "        columns = X.columns\n",
    "        y = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"y.csv\").to_numpy()\n",
    "        y1 = []\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            y1.append(y[i][0])\n",
    "        y = np.array(y1)\n",
    "        y = y.astype(int)\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        X = enc.fit_transform(X).toarray()\n",
    "\n",
    "    else:\n",
    "        X = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"X.csv\")\n",
    "        columns = X.columns\n",
    "        y = pd.read_csv(DATA_DIR + \"/\" + DATASET + \"/\" + \"y.csv\").to_numpy()\n",
    "        y1 = []\n",
    "        for i in range(len(y)):\n",
    "            y1.append(y[i][0])\n",
    "        y = np.array(y1)\n",
    "\n",
    "    # X = drop_constant_column(X)\n",
    "    X = X.to_numpy()\n",
    "    return X, y, columns\n",
    "\n",
    "\n",
    "def create_imbalanced_data_clusters(n_samples=1000, n_features=8, n_informative=5, n_classes=2,\\\n",
    "                            n_clusters = 2, frac=0.4, outer_class_sep=0.5, inner_class_sep=0.2, clus_per_class=2, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    X = np.empty(shape=n_features)\n",
    "    Y = np.empty(shape=1)\n",
    "    offsets = np.random.normal(0, outer_class_sep, size=(n_clusters, n_features))\n",
    "    for i in range(n_clusters):\n",
    "        samples = int(np.random.normal(n_samples, n_samples/10))\n",
    "        x, y = make_classification(n_samples=samples, n_features=n_features, n_informative=n_informative,\\\n",
    "                                    n_classes=n_classes, class_sep=inner_class_sep, n_clusters_per_class=clus_per_class)\n",
    "                                    # n_repeated=0, n_redundant=0)\n",
    "        x += offsets[i]\n",
    "        y_0 = np.where(y == 0)[0]\n",
    "        y_1 = np.where(y != 0)[0]\n",
    "        y_1 = np.random.choice(y_1, int(np.random.normal(frac, frac/4)*len(y_1)))\n",
    "        index = np.hstack([y_0,y_1])\n",
    "        np.random.shuffle(index)\n",
    "        x_new = x[index]\n",
    "        y_new = y[index]\n",
    "\n",
    "        X = np.vstack((X,x_new))\n",
    "        Y = np.hstack((Y,y_new))\n",
    "\n",
    "    X = pd.DataFrame(X[1:,:])\n",
    "    Y = Y[1:]\n",
    "    columns = [\"feature_\"+str(i) for i in range(n_features)]\n",
    "    return X, np.array(Y).astype('int'), columns\n",
    "\n",
    "\n",
    "def get_train_val_test_loaders(args):\n",
    "    if args.dataset in DATASETS:\n",
    "        if args.dataset != \"aki\" and args.dataset != \"ards\":\n",
    "            print(\"Loading Dataset \", args.dataset)\n",
    "            if args.dataset == \"synthetic\":\n",
    "                n_feat = 45\n",
    "                X, y, columns = create_imbalanced_data_clusters(n_samples=5000,\\\n",
    "                       n_clusters=args.n_clusters, n_features = n_feat,\\\n",
    "                       inner_class_sep=0.2, outer_class_sep=2, seed=0)\n",
    "                args.input_dim = n_feat\n",
    "\n",
    "            elif args.dataset == \"paper_synthetic\":\n",
    "                n_feat = 100\n",
    "                X, y = paper_synthetic(2500, centers=4)\n",
    "                args.input_dim = n_feat\n",
    "                print(args.input_dim)\n",
    "\n",
    "            else:\n",
    "                X, y, columns = get_dataset(args.dataset, DATA_DIR)\n",
    "                print(args.dataset)\n",
    "                args.input_dim = X.shape[1]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)\n",
    "\n",
    "            sc = StandardScaler()\n",
    "            X_train = sc.fit_transform(X_train)\n",
    "            X_val = sc.fit_transform(X_val)\n",
    "            X_test = sc.fit_transform(X_test)\n",
    "            X_train_data_loader = list(zip(X_train.astype(np.float32), y_train, range(len(X_train))))\n",
    "            X_val_data_loader = list(zip(X_val.astype(np.float32), y_val, range(len(X_val))))\n",
    "            X_test_data_loader  = list(zip(X_test.astype(np.float32), y_test, range(len(X_train))))\n",
    "\n",
    "        elif args.dataset == \"aki\":\n",
    "            print(\"Loading aki Train\")\n",
    "            X, y, columns = get_dataset(args.dataset, DATA_DIR)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)\n",
    "\n",
    "            args.input_dim = X_train.shape[1]\n",
    "\n",
    "            X_train_data_loader = list(zip(X_train.astype(np.float32), y_train, range(len(X_train))))\n",
    "            X_val_data_loader = list(zip(X_val.astype(np.float32), y_val, range(len(X_val))))\n",
    "            X_test_data_loader  = list(zip(X_test.astype(np.float32), y_test, range(len(X_train))))\n",
    "\n",
    "        else:\n",
    "            print(\"Loading ards Train\")\n",
    "            X, y, columns = get_dataset(args.dataset, DATA_DIR)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)\n",
    "\n",
    "            args.input_dim = X_train.shape[1]\n",
    "\n",
    "            X_train_data_loader = list(zip(X_train.astype(np.float32), y_train, range(len(X_train))))\n",
    "            X_val_data_loader = list(zip(X_val.astype(np.float32), y_val, range(len(X_val))))\n",
    "            X_test_data_loader  = list(zip(X_test.astype(np.float32), y_test, range(len(X_train))))\n",
    "\n",
    "            \n",
    "        train_loader = torch.utils.data.DataLoader(X_train_data_loader,\n",
    "            batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(X_val_data_loader,\n",
    "            batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(X_test_data_loader, \n",
    "            batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "        return columns, (X_train, y_train, train_loader), (X_val, y_val, val_loader), (X_test, y_test, test_loader)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def paper_synthetic(n_pts=1000, centers=4):\n",
    "    X, y = make_blobs(n_pts, centers=centers)\n",
    "    W = np.random.randn(10,2)\n",
    "    U = np.random.randn(100,10)\n",
    "    X1 = W.dot(X.T)\n",
    "    X1 = X1*(X1>0)\n",
    "    X2 = U.dot(X1)\n",
    "    X2 = X2*(X2>0)\n",
    "    return X2.T, y\n",
    "\n",
    "## Ablation Parameter Ranges ##\n",
    "betas = [0, 0.001, 0.002, 0.005, 0.008, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
    "gammas = [0, 0.001, 0.002, 0.005, 0.008, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
    "deltas = [0, 0.001, 0.002, 0.005, 0.008, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
    "ks = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     3,
     72
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStoppingCAC:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='./pretrained_model/checkpoint', dataset=\"\", trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = [None, None]\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path + \"_\" + dataset\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = val_loss\n",
    "        if self.best_score[0] is None:\n",
    "            self.best_score[0] = score[0]\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        if self.best_score[1] is None:\n",
    "            self.best_score[1] = score[1]\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        if score[1] < self.best_score[1] + self.delta :\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.ae.state_dict(), self.path+\".pt\")\n",
    "        for j in range(model.n_clusters):\n",
    "            torch.save(model.classifiers[j][0].state_dict(), self.path+\"_\"+str(j)+\".pt\")\n",
    "        self.val_loss_min = val_loss\n",
    "        torch.save(model.cluster_layer, self.path+\"_cc\"+\".pt\")\n",
    "        torch.save(model.p_cluster_layer, self.path+\"_pc\"+\".pt\")\n",
    "        torch.save(model.n_cluster_layer, self.path+\"_nc\"+\".pt\")\n",
    "\n",
    "    def load_checkpoint(self, model):\n",
    "        print(\"Loading Best model with score: \", self.best_score)\n",
    "        model.ae.load_state_dict(torch.load(self.path+\".pt\"))\n",
    "        for j in range(model.n_clusters):\n",
    "            model.classifiers[j][0].load_state_dict(torch.load(self.path+\"_\"+str(j)+\".pt\"))\n",
    "        model.cluster_layer = torch.load(self.path+\"_cc\"+\".pt\")\n",
    "        model.p_cluster_layer = torch.load(self.path+\"_pc\"+\".pt\")\n",
    "        model.n_cluster_layer = torch.load(self.path+\"_nc\"+\".pt\")\n",
    "        return model\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='./pretrained_model/checkpoint', dataset=\"\", trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = [None, None]\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path + \"_\" + dataset\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = val_loss\n",
    "        if self.best_score[0] is None:\n",
    "            self.best_score[0] = score[0]\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        if self.best_score[1] is None:\n",
    "            self.best_score[1] = score[1]\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        if score[1] < self.best_score[1] + self.delta :\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path+\".pt\")\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "    def load_checkpoint(self, model):\n",
    "        print(\"Loading Best model with score: \", self.best_score)\n",
    "        model.load_state_dict(torch.load(self.path+\".pt\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     9,
     61,
     86,
     128
    ]
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "import torch\n",
    "from utils import is_non_zero_file\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3,\n",
    "                 input_dim, n_z):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.enc_1 = Linear(input_dim, n_enc_1)\n",
    "        self.enc_2 = Linear(n_enc_1, n_enc_2)\n",
    "        self.enc_3 = Linear(n_enc_2, n_enc_3)\n",
    "\n",
    "        self.z_layer = Linear(n_enc_3, n_z)\n",
    "\n",
    "        # decoder\n",
    "        self.dec_1 = Linear(n_z, n_dec_1)\n",
    "        self.dec_2 = Linear(n_dec_1, n_dec_2)\n",
    "        self.dec_3 = Linear(n_dec_2, n_dec_3)\n",
    "\n",
    "        self.x_bar_layer = Linear(n_dec_3, input_dim)\n",
    "\n",
    "    def forward(self, x, output=\"decoded\"):\n",
    "\n",
    "        # encoder\n",
    "        enc_h1 = F.relu(self.enc_1(x))\n",
    "        enc_h2 = F.relu(self.enc_2(enc_h1))\n",
    "        enc_h3 = F.relu(self.enc_3(enc_h2))\n",
    "\n",
    "        z = self.z_layer(enc_h3)\n",
    "        if output == \"latent\":\n",
    "            return z\n",
    "\n",
    "        # decoder\n",
    "        dec_h1 = F.relu(self.dec_1(z))\n",
    "        dec_h2 = F.relu(self.dec_2(dec_h1))\n",
    "        dec_h3 = F.relu(self.dec_3(dec_h2))\n",
    "        x_bar = self.x_bar_layer(dec_h3)\n",
    "\n",
    "        return x_bar, z\n",
    "\n",
    "\n",
    "def target_distribution(q):\n",
    "    weight = q**2 / q.sum(0)\n",
    "    return (weight.t() / weight.sum(1)).t()\n",
    "\n",
    "\n",
    "def source_distribution(z, cluster_layer, alpha=1):\n",
    "    q = 1.0 / (1.0 + torch.sum(\n",
    "        torch.pow(z.unsqueeze(1) - cluster_layer, 2), 2) / alpha)\n",
    "    q = q.pow((alpha + 1.0) / 2.0)\n",
    "    q = (q.t() / torch.sum(q, 1)).t()\n",
    "    return q\n",
    "\n",
    "\n",
    "def pretrain_ae(model, train_loader, args):\n",
    "    '''\n",
    "    pretrain autoencoder\n",
    "    '''\n",
    "    print(model)\n",
    "    optimizer = Adam(model.parameters(), lr=args.lr)\n",
    "    for epoch in range(50):\n",
    "        total_loss = 0.\n",
    "        for batch_idx, (x, _, _) in enumerate(train_loader):\n",
    "            x = x.to(args.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            x_bar, _ = model(x)\n",
    "            loss = F.mse_loss(x_bar, x)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Pretraining epoch {} loss={:.4f}\".format(epoch,\n",
    "                                            total_loss / (batch_idx + 1)))\n",
    "        torch.save(model.state_dict(), args.pretrain_path)\n",
    "    print(\"model saved to {}.\".format(args.pretrain_path))\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self, args, input_dim, ae=None):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.args = args\n",
    "        self.n_classes = args.n_classes\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "        self.ae = ae\n",
    "\n",
    "        if self.ae == None:\n",
    "            self.input_dim = args.input_dim\n",
    "        else:\n",
    "            self.input_dim = args.latent_dim\n",
    "        if input_dim != None:\n",
    "            self.input_dim = input_dim\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, args.n_classes),\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.classifier.parameters(), lr=args.lr)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.ae == None:\n",
    "            return self.classifier(inputs)\n",
    "        else:\n",
    "            input_z = self.ae(inputs, output=\"latent\")\n",
    "            return self.classifier(input_z)\n",
    "\n",
    "    def fit(self, X_batch, y_batch):\n",
    "        self.optimizer.zero_grad()\n",
    "        self.classifier.train()\n",
    "        y_pred = self.forward(X_batch.detach())\n",
    "        train_loss = self.criterion(y_pred, y_batch)\n",
    "        train_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return y_pred.detach().numpy(), train_loss.item()\n",
    "\n",
    "\n",
    "class MultiHeadIDEC(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_enc_1,\n",
    "                 n_enc_2,\n",
    "                 n_enc_3,\n",
    "                 n_dec_1,\n",
    "                 n_dec_2,\n",
    "                 n_dec_3,\n",
    "                 args):\n",
    "        super(MultiHeadIDEC, self).__init__()\n",
    "        self.alpha = args.alpha\n",
    "        self.pretrain_path = args.pretrain_path\n",
    "        self.device = args.device\n",
    "        self.n_clusters = args.n_clusters\n",
    "        self.input_dim = args.input_dim\n",
    "        self.n_z = args.n_z\n",
    "        self.args = args\n",
    "\n",
    "        self.ae = AE(\n",
    "            n_enc_1=n_enc_1,\n",
    "            n_enc_2=n_enc_2,\n",
    "            n_enc_3=n_enc_3,\n",
    "            n_dec_1=n_dec_1,\n",
    "            n_dec_2=n_dec_2,\n",
    "            n_dec_3=n_dec_3,\n",
    "            input_dim=self.input_dim,\n",
    "            n_z=self.n_z)\n",
    "\n",
    "        # cluster layer\n",
    "        self.cluster_layer = torch.Tensor(self.n_clusters, self.n_z)\n",
    "        self.p_cluster_layer = torch.Tensor(self.n_clusters, self.n_z)\n",
    "        self.n_cluster_layer = torch.Tensor(self.n_clusters, self.n_z)\n",
    "        torch.nn.init.xavier_normal_(self.cluster_layer.data)\n",
    "        torch.nn.init.xavier_normal_(self.p_cluster_layer.data)\n",
    "        torch.nn.init.xavier_normal_(self.n_cluster_layer.data)\n",
    "        \n",
    "        self.classifiers = []\n",
    "        for _ in range(self.n_clusters):\n",
    "            classifier = nn.Sequential(\n",
    "                nn.Linear(self.n_z, 64),\n",
    "                nn.ReLU(),\n",
    "                # nn.Linear(128, 64),\n",
    "                # nn.ReLU(),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 8),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(8, args.n_classes),\n",
    "            ).to(self.device)\n",
    "\n",
    "            # classifier = nn.Sequential(\n",
    "            #     nn.Linear(self.n_z, 100),\n",
    "            #     nn.ReLU(),\n",
    "            #     nn.Linear(100, 100),\n",
    "            #     nn.ReLU(),\n",
    "            #     nn.Linear(100, 50),\n",
    "            #     nn.ReLU(),\n",
    "            #     nn.Linear(50, args.n_classes),\n",
    "            # )\n",
    "            optimizer = torch.optim.Adam(classifier.parameters(), lr=args.lr)\n",
    "            self.classifiers.append([classifier, optimizer])\n",
    "            \n",
    "\n",
    "    def pretrain(self, train_loader, path=''):\n",
    "        print(path)\n",
    "        if not is_non_zero_file(path):\n",
    "            path = ''\n",
    "        if path == '':\n",
    "            pretrain_ae(self.ae, train_loader, self.args)\n",
    "        else:\n",
    "            # load pretrain weights\n",
    "            self.ae.load_state_dict(torch.load(self.pretrain_path))\n",
    "            print('load pretrained ae from', path)\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        qs, z_test = self.forward(X_test)\n",
    "        q_test = qs[0]\n",
    "        cluster_ids = torch.argmax(q_test, axis=1)\n",
    "        preds = torch.zeros((self.n_clusters, 2))\n",
    "        for j in range(self.n_clusters):\n",
    "            preds[j,:] = self.classifiers[cluster_ids[j]]\n",
    "        return preds\n",
    "\n",
    "\n",
    "    def forward(self, x, output=\"default\"):\n",
    "        x_bar, z = self.ae(x)\n",
    "        # Cluster\n",
    "        q   = source_distribution(z, self.cluster_layer, alpha=self.alpha)\n",
    "        q_p = source_distribution(z, self.p_cluster_layer, alpha=self.alpha)\n",
    "        q_n = source_distribution(z, self.n_cluster_layer, alpha=self.alpha)\n",
    "\n",
    "        if output == \"latent\":\n",
    "            return (q, q_p, q_n), z\n",
    "\n",
    "        elif output == \"classifier\":\n",
    "            preds = torch.zeros((len(z), 2))\n",
    "            for j in range(len(z)):\n",
    "                preds[j,:] = self.classifiers[j](z)\n",
    "            return preds\n",
    "        \n",
    "        else:\n",
    "            return z, x_bar, (q, q_p, q_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "params = {\n",
    "'dir' : 'synthetic',\n",
    "'dataset' : 'cic',\n",
    "\n",
    "# Training parameters\n",
    "'lr' : 0.002,\n",
    "'alpha' : 1,\n",
    "'wd' : 5e-4,\n",
    "'batch_size' : 512,\n",
    "'n_epochs' : 100,\n",
    "'pre_epoch' : 40,\n",
    "'pretrain' : True,\n",
    "\"load_ae\": False,\n",
    "\"classifier\": \"LR\",\n",
    "\"tol\": 0.01,\n",
    "\"attention\": \"True\",\n",
    "\n",
    "# Model parameters\n",
    "'lamda' : 1,\n",
    "'beta' : 0.5, # KL loss/KM loss weight\n",
    "'gamma' : 1.5, # Classification loss weight\n",
    "'delta' : 1, # Class Balance weight\n",
    "'eta' : 0.0, # Class separation weight\n",
    "'hidden_dims' : [64, 32],\n",
    "'n_z' : 20,\n",
    "'n_clusters' : 3,\n",
    "'clustering' : 'cac',\n",
    "'n_classes'  : 2,\n",
    "\n",
    "# Utility parameters\n",
    "'n_jobs' : 6,\n",
    "'device' : 'cpu',\n",
    "'log_interval' : 2,   \n",
    "'cluster_balance' : 'hellinger',\n",
    "'pretrain_path': '/Users/shivin/Document/NUS/Research/CAC/CAC_DL/DeepCAC/pretrained_model'}\n",
    "# 'pretrain_path': ''}\n",
    "\n",
    "\n",
    "class parameters(object):\n",
    "    def __init__(self, params):\n",
    "        self.dir = params['dir']\n",
    "        self.input_dim = -1\n",
    "        self.dataset = params['dataset']\n",
    "        \n",
    "        # Training parameters\n",
    "        self.lr = params['lr']\n",
    "        self.alpha = params['alpha']\n",
    "        self.wd = params['wd']\n",
    "        self.batch_size = params['batch_size']\n",
    "        self.n_epochs = params['n_epochs']\n",
    "        self.pre_epoch = params['pre_epoch']\n",
    "        self.pretrain = params['pretrain']\n",
    "        self.load_ae = params['load_ae']\n",
    "        self.classifier = params['classifier']\n",
    "        self.tol = params['tol']\n",
    "        self.attention = params['attention'] == \"True\"\n",
    "\n",
    "        # Model parameters\n",
    "        self.lamda = params['lamda']\n",
    "        self.beta = params['beta']\n",
    "        self.gamma = params['gamma']\n",
    "        self.delta = params['delta']\n",
    "        self.eta = params['eta']\n",
    "        self.hidden_dims = params['hidden_dims']\n",
    "        self.latent_dim = self.n_z = params['n_z']\n",
    "        self.n_clusters = params['n_clusters']\n",
    "        self.clustering = params['clustering']\n",
    "        self.n_classes = params['n_classes']\n",
    "        self.cluster_balance = params['cluster_balance']\n",
    "\n",
    "        # Utility parameters\n",
    "        self.n_jobs = params['n_jobs']\n",
    "        self.device = params['device']\n",
    "        self.log_interval = params['log_interval']\n",
    "        self.pretrain_path = params['pretrain_path'] + \"/\" + self.dataset + \".pth\"\n",
    "\n",
    "args = parameters(params)\n",
    "datasets = ['titanic', 'magic', 'creditcard', 'adult', 'diabetes',\\\n",
    "            'cic', 'sepsis', 'synthetic', 'paper_synthetic', 'aki', 'infant', 'wid_mortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset  cic\n",
      "cic\n"
     ]
    }
   ],
   "source": [
    "suffix = \"\"\n",
    "suffix += args.dataset + \"_\"\n",
    "suffix += str(args.n_clusters) + \"_\"\n",
    "suffix += str(args.attention)\n",
    "\n",
    "column_names, train_data, val_data, test_data = get_train_val_test_loaders(args)\n",
    "os.chdir(BASE_DIR)\n",
    "X_train, y_train, train_loader = train_data\n",
    "X_val, y_val, val_loader = val_data\n",
    "X_test, y_test, test_loader = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "(6750, 117)\n",
      "0.14133333333333334\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train)+len(X_val)+len(X_test))\n",
    "print(X_train.shape)\n",
    "print(sum(y_train)/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_kidney' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f3979139f7c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# y_test_kidney = y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# test_loader_kidney = test_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_kidney\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_kidney\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader_kidney\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_kidney' is not defined"
     ]
    }
   ],
   "source": [
    "# X_train_kidney = X_train\n",
    "# y_train_kidney = y_train\n",
    "# train_loader_kidney = train_loader\n",
    "# X_val_kidney = X_val\n",
    "# y_val_kidney = y_val\n",
    "# val_loader_kidney = val_loader\n",
    "# X_test_kidney = X_test\n",
    "# y_test_kidney = y_test\n",
    "# test_loader_kidney = test_loader\n",
    "X_train = X_train_kidney\n",
    "y_train = y_train_kidney\n",
    "train_loader = train_loader_kidney\n",
    "X_val = X_val_kidney\n",
    "y_val = y_val_kidney\n",
    "val_loader = val_loader_kidney\n",
    "X_test = X_test_kidney\n",
    "y_test = y_test_kidney\n",
    "test_loader = test_loader_kidney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAPS-I</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>Length_of_stay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>CCU</th>\n",
       "      <th>CSRU</th>\n",
       "      <th>SICU</th>\n",
       "      <th>...</th>\n",
       "      <th>SysABP_last</th>\n",
       "      <th>TroponinI_last</th>\n",
       "      <th>TroponinT_last</th>\n",
       "      <th>WBC_last</th>\n",
       "      <th>Weight_last</th>\n",
       "      <th>pH_last</th>\n",
       "      <th>MechVentStartTime</th>\n",
       "      <th>MechVentDuration</th>\n",
       "      <th>MechVentLast8Hour</th>\n",
       "      <th>UrineOutputSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.770832</td>\n",
       "      <td>-0.101649</td>\n",
       "      <td>1.094800</td>\n",
       "      <td>0.309861</td>\n",
       "      <td>-1.126133</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>-0.687584</td>\n",
       "      <td>-0.411137</td>\n",
       "      <td>-0.527874</td>\n",
       "      <td>1.605928</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.489278</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>0.389274</td>\n",
       "      <td>-0.915594</td>\n",
       "      <td>0.938981</td>\n",
       "      <td>-0.516772</td>\n",
       "      <td>0.963687</td>\n",
       "      <td>0.984411</td>\n",
       "      <td>1.464460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.062360</td>\n",
       "      <td>-0.338981</td>\n",
       "      <td>-0.261159</td>\n",
       "      <td>1.477449</td>\n",
       "      <td>-1.126133</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>-0.786423</td>\n",
       "      <td>-0.411137</td>\n",
       "      <td>-0.527874</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.282146</td>\n",
       "      <td>-0.077343</td>\n",
       "      <td>-1.051297</td>\n",
       "      <td>-0.008595</td>\n",
       "      <td>-0.013013</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.022693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.228828</td>\n",
       "      <td>-0.101649</td>\n",
       "      <td>-0.487152</td>\n",
       "      <td>-0.332313</td>\n",
       "      <td>0.888652</td>\n",
       "      <td>0.029664</td>\n",
       "      <td>0.206465</td>\n",
       "      <td>-0.411137</td>\n",
       "      <td>1.894390</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.097559</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.225295</td>\n",
       "      <td>0.386145</td>\n",
       "      <td>1.308358</td>\n",
       "      <td>-0.447348</td>\n",
       "      <td>-1.917657</td>\n",
       "      <td>-1.596249</td>\n",
       "      <td>-1.770497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.270747</td>\n",
       "      <td>1.322345</td>\n",
       "      <td>-0.185828</td>\n",
       "      <td>0.718516</td>\n",
       "      <td>-1.126133</td>\n",
       "      <td>-0.079038</td>\n",
       "      <td>-1.208737</td>\n",
       "      <td>-0.411137</td>\n",
       "      <td>1.894390</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.901699</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.407389</td>\n",
       "      <td>-0.659267</td>\n",
       "      <td>1.123670</td>\n",
       "      <td>-0.102710</td>\n",
       "      <td>0.871199</td>\n",
       "      <td>0.984411</td>\n",
       "      <td>0.817469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.728913</td>\n",
       "      <td>-0.576313</td>\n",
       "      <td>0.492152</td>\n",
       "      <td>-1.091245</td>\n",
       "      <td>-1.126133</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>1.136455</td>\n",
       "      <td>2.432280</td>\n",
       "      <td>-0.527874</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.464293</td>\n",
       "      <td>1.270724</td>\n",
       "      <td>0.569605</td>\n",
       "      <td>-0.013013</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.022693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6745</th>\n",
       "      <td>0.270917</td>\n",
       "      <td>-0.576313</td>\n",
       "      <td>-0.637814</td>\n",
       "      <td>1.068793</td>\n",
       "      <td>-1.126133</td>\n",
       "      <td>-0.294311</td>\n",
       "      <td>-1.631052</td>\n",
       "      <td>-0.411137</td>\n",
       "      <td>-0.527874</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>12.511250</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.999195</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>-2.200720</td>\n",
       "      <td>-0.013013</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.022693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>-0.728913</td>\n",
       "      <td>0.135684</td>\n",
       "      <td>-0.185828</td>\n",
       "      <td>-1.675039</td>\n",
       "      <td>0.888652</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>0.166031</td>\n",
       "      <td>-0.411137</td>\n",
       "      <td>-0.527874</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>...</td>\n",
       "      <td>1.497578</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.384627</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.384917</td>\n",
       "      <td>-0.293625</td>\n",
       "      <td>-0.914522</td>\n",
       "      <td>-1.596249</td>\n",
       "      <td>-0.692178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6747</th>\n",
       "      <td>1.937300</td>\n",
       "      <td>1.322345</td>\n",
       "      <td>0.567483</td>\n",
       "      <td>1.010413</td>\n",
       "      <td>-1.126133</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>-1.316562</td>\n",
       "      <td>-0.411137</td>\n",
       "      <td>-0.527874</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314121</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>0.685177</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>-0.353837</td>\n",
       "      <td>-0.581237</td>\n",
       "      <td>1.134433</td>\n",
       "      <td>0.984411</td>\n",
       "      <td>0.386141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6748</th>\n",
       "      <td>-0.395636</td>\n",
       "      <td>-0.338981</td>\n",
       "      <td>-0.637814</td>\n",
       "      <td>-1.733419</td>\n",
       "      <td>-1.126133</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>-0.418021</td>\n",
       "      <td>-0.411137</td>\n",
       "      <td>-0.527874</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.578102</td>\n",
       "      <td>-0.639163</td>\n",
       "      <td>-0.723213</td>\n",
       "      <td>-0.013013</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.022693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>1.270747</td>\n",
       "      <td>1.797010</td>\n",
       "      <td>-0.788476</td>\n",
       "      <td>0.601758</td>\n",
       "      <td>0.888652</td>\n",
       "      <td>-0.241026</td>\n",
       "      <td>0.884863</td>\n",
       "      <td>-0.411137</td>\n",
       "      <td>1.894390</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.832031</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.578102</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.938981</td>\n",
       "      <td>0.770043</td>\n",
       "      <td>0.494135</td>\n",
       "      <td>0.984411</td>\n",
       "      <td>0.386141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6750 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SAPS-I      SOFA  Length_of_stay       Age    Gender    Height  \\\n",
       "0     0.770832 -0.101649        1.094800  0.309861 -1.126133  0.014443   \n",
       "1    -0.062360 -0.338981       -0.261159  1.477449 -1.126133  0.014443   \n",
       "2    -1.228828 -0.101649       -0.487152 -0.332313  0.888652  0.029664   \n",
       "3     1.270747  1.322345       -0.185828  0.718516 -1.126133 -0.079038   \n",
       "4    -0.728913 -0.576313        0.492152 -1.091245 -1.126133  0.014443   \n",
       "...        ...       ...             ...       ...       ...       ...   \n",
       "6745  0.270917 -0.576313       -0.637814  1.068793 -1.126133 -0.294311   \n",
       "6746 -0.728913  0.135684       -0.185828 -1.675039  0.888652  0.014443   \n",
       "6747  1.937300  1.322345        0.567483  1.010413 -1.126133  0.014443   \n",
       "6748 -0.395636 -0.338981       -0.637814 -1.733419 -1.126133  0.014443   \n",
       "6749  1.270747  1.797010       -0.788476  0.601758  0.888652 -0.241026   \n",
       "\n",
       "        Weight       CCU      CSRU      SICU  ...  SysABP_last  \\\n",
       "0    -0.687584 -0.411137 -0.527874  1.605928  ...    -1.489278   \n",
       "1    -0.786423 -0.411137 -0.527874 -0.622693  ...     0.002283   \n",
       "2     0.206465 -0.411137  1.894390 -0.622693  ...    -1.097559   \n",
       "3    -1.208737 -0.411137  1.894390 -0.622693  ...    -0.901699   \n",
       "4     1.136455  2.432280 -0.527874 -0.622693  ...     0.002283   \n",
       "...        ...       ...       ...       ...  ...          ...   \n",
       "6745 -1.631052 -0.411137 -0.527874 -0.622693  ...     0.002283   \n",
       "6746  0.166031 -0.411137 -0.527874 -0.622693  ...     1.497578   \n",
       "6747 -1.316562 -0.411137 -0.527874 -0.622693  ...    -0.314121   \n",
       "6748 -0.418021 -0.411137 -0.527874 -0.622693  ...     0.002283   \n",
       "6749  0.884863 -0.411137  1.894390 -0.622693  ...    -1.832031   \n",
       "\n",
       "      TroponinI_last  TroponinT_last  WBC_last  Weight_last   pH_last  \\\n",
       "0          -0.025645       -0.002033  0.389274    -0.915594  0.938981   \n",
       "1          -0.025645       -0.282146 -0.077343    -1.051297 -0.008595   \n",
       "2          -0.025645       -0.002033 -0.225295     0.386145  1.308358   \n",
       "3          -0.025645       -0.002033 -0.407389    -0.659267  1.123670   \n",
       "4          -0.025645       -0.002033 -0.464293     1.270724  0.569605   \n",
       "...              ...             ...       ...          ...       ...   \n",
       "6745       12.511250       -0.002033 -0.999195     0.016096 -2.200720   \n",
       "6746       -0.025645       -0.002033 -0.384627     0.016096  0.384917   \n",
       "6747       -0.025645       -0.002033  0.685177     0.016096 -0.353837   \n",
       "6748       -0.025645       -0.002033 -0.578102    -0.639163 -0.723213   \n",
       "6749       -0.025645       -0.002033 -0.578102     0.016096  0.938981   \n",
       "\n",
       "      MechVentStartTime  MechVentDuration  MechVentLast8Hour  UrineOutputSum  \n",
       "0             -0.516772          0.963687           0.984411        1.464460  \n",
       "1             -0.013013          0.013206           0.005821        0.022693  \n",
       "2             -0.447348         -1.917657          -1.596249       -1.770497  \n",
       "3             -0.102710          0.871199           0.984411        0.817469  \n",
       "4             -0.013013          0.013206           0.005821        0.022693  \n",
       "...                 ...               ...                ...             ...  \n",
       "6745          -0.013013          0.013206           0.005821        0.022693  \n",
       "6746          -0.293625         -0.914522          -1.596249       -0.692178  \n",
       "6747          -0.581237          1.134433           0.984411        0.386141  \n",
       "6748          -0.013013          0.013206           0.005821        0.022693  \n",
       "6749           0.770043          0.494135           0.984411        0.386141  \n",
       "\n",
       "[6750 rows x 117 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_resp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-59789a1860d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# y_test_resp = y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# test_loader_resp = test_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_resp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_resp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader_resp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_resp' is not defined"
     ]
    }
   ],
   "source": [
    "# X_train_resp = X_train\n",
    "# y_train_resp = y_train\n",
    "# train_loader_resp = train_loader\n",
    "# X_val_resp = X_val\n",
    "# y_val_resp = y_val\n",
    "# val_loader_resp = val_loader\n",
    "# X_test_resp = X_test\n",
    "# y_test_resp = y_test\n",
    "# test_loader_resp = test_loader\n",
    "X_train = X_train_resp\n",
    "y_train = y_train_resp\n",
    "train_loader = train_loader_resp\n",
    "X_val = X_val_resp\n",
    "y_val = y_val_resp\n",
    "val_loader = val_loader_resp\n",
    "X_test = X_test_resp\n",
    "y_test = y_test_resp\n",
    "test_loader = test_loader_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SAPS-I', 'SOFA', 'Length_of_stay', 'Age', 'Gender', 'Height', 'Weight',\n",
      "       'CCU', 'CSRU', 'SICU',\n",
      "       ...\n",
      "       'SysABP_last', 'TroponinI_last', 'TroponinT_last', 'WBC_last',\n",
      "       'Weight_last', 'pH_last', 'MechVentStartTime', 'MechVentDuration',\n",
      "       'MechVentLast8Hour', 'UrineOutputSum'],\n",
      "      dtype='object', length=117)\n",
      "(6750, 117)\n"
     ]
    }
   ],
   "source": [
    "print(column_names)\n",
    "args.input_dim = X_train.shape[1]\n",
    "BASE_DIR = \"/Users/shivin/Document/NUS/Research/cac/cac_dl/DeepCAC\"\n",
    "os.chdir(BASE_DIR)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiHead IDEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     37
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shivin/Document/NUS/Research/CAC/CAC_DL/DeepCAC/pretrained_model/cic.pth\n",
      "load pretrained ae from /Users/shivin/Document/NUS/Research/CAC/CAC_DL/DeepCAC/pretrained_model/cic.pth\n",
      "[4658  203 1889]\n"
     ]
    }
   ],
   "source": [
    "f1_scores, auc_scores, acc_scores , sil_scores, mifd_scores,\\\n",
    "nhfd_scores, w_nhfd_scores = [], [], [], [], [], [], []\n",
    "\n",
    "# to track the training loss as the model trains\n",
    "train_losses, e_train_losses = [], []\n",
    "test_losses, e_test_losses, local_sum_test_losses = [], [], []\n",
    "model_complexity = []\n",
    "\n",
    "model = MultiHeadIDEC(\n",
    "        n_enc_1=128,\n",
    "        n_enc_2=64,\n",
    "        n_enc_3=32,\n",
    "        n_dec_1=32,\n",
    "        n_dec_2=64,\n",
    "        n_dec_3=128,\n",
    "        args=args).to(args.device)\n",
    "\n",
    "model.pretrain(train_loader, args.pretrain_path)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# cluster parameter initiate\n",
    "device = args.device\n",
    "y = y_train\n",
    "_, ori_hidden = model.ae(torch.Tensor(X_train).to(args.device))\n",
    "_, ori_hidden_val = model.ae(torch.Tensor(X_val).to(args.device))\n",
    "\n",
    "kmeans = KMeans(n_clusters=args.n_clusters, n_init=20)\n",
    "_ = kmeans.fit_predict(ori_hidden.data.cpu().numpy())\n",
    "\n",
    "ori_cluster_indices = kmeans.labels_\n",
    "original_cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "print(np.bincount(ori_cluster_indices))\n",
    "\n",
    "ori_val_cluster_indices = kmeans.fit_predict(ori_hidden_val.data.cpu().numpy())\n",
    "\n",
    "model.cluster_layer.data = torch.tensor(original_cluster_centers).to(device)\n",
    "\n",
    "## Initialization ##\n",
    "for i in range(args.n_clusters):\n",
    "    cluster_idx = np.where(ori_cluster_indices == i)[0]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     157
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "qval tensor([1311.5187,  151.7287,  786.7526], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [1513   56  681]\n",
      "KL div tensor([-437.5391,  -50.9424, -262.6171], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[  0/100] train_loss: 0.571 valid_loss: 1307.641 valid_F1: 0.000 valid_AUC: 0.420 valid_Feature_p: 0.066 valid_MIFD: 0.534 valid_Silhouette: 0.255 Complexity Term: 0.000\n",
      "Epoch: 00 | Loss: 88.368 | KM Loss: 900.162 | Classification Loss: 562.903 | Cluster Balance Loss: 4.584\n",
      "Epoch: 01 | Loss: 144.461 | KM Loss: 553.735 | Classification Loss: 315.878 | Cluster Balance Loss: 1.003\n",
      "qval tensor([826.1276, 652.9210, 770.9514], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [1621  627    2]\n",
      "KL div tensor([-275.7421, -218.0066, -257.3500], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[  2/100] train_loss: 0.388 valid_loss: 856.715 valid_F1: 0.000 valid_AUC: 0.715 valid_Feature_p: 0.006 valid_MIFD: 0.274 valid_Silhouette: 0.252 Complexity Term: 0.000\n",
      "Epoch: 02 | Loss: 166.268 | KM Loss: 540.310 | Classification Loss: 298.878 | Cluster Balance Loss: 2.208\n",
      "Epoch: 03 | Loss: 146.702 | KM Loss: 499.959 | Classification Loss: 278.373 | Cluster Balance Loss: 1.915\n",
      "qval tensor([801.9783, 693.2425, 754.7792], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [1085 1149   16]\n",
      "KL div tensor([-267.6923, -231.4471, -251.9593], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[  4/100] train_loss: 0.322 valid_loss: 714.026 valid_F1: 0.000 valid_AUC: 0.836 valid_Feature_p: 0.000 valid_MIFD: 0.469 valid_Silhouette: 0.200 Complexity Term: 0.000\n",
      "Epoch: 04 | Loss: 93.282 | KM Loss: 423.849 | Classification Loss: 246.004 | Cluster Balance Loss: 0.856\n",
      "Epoch: 05 | Loss: 75.377 | KM Loss: 392.929 | Classification Loss: 231.532 | Cluster Balance Loss: 0.709\n",
      "qval tensor([789.4905, 693.7668, 766.7427], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [1054 1146   50]\n",
      "KL div tensor([-263.5297, -231.6218, -255.9471], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[  6/100] train_loss: 0.284 valid_loss: 679.099 valid_F1: 0.372 valid_AUC: 0.854 valid_Feature_p: 0.000 valid_MIFD: 0.523 valid_Silhouette: 0.062 Complexity Term: 0.000\n",
      "Epoch: 06 | Loss: 65.678 | KM Loss: 369.488 | Classification Loss: 219.402 | Cluster Balance Loss: 0.520\n",
      "Epoch: 07 | Loss: 58.653 | KM Loss: 345.694 | Classification Loss: 205.779 | Cluster Balance Loss: 0.828\n",
      "qval tensor([785.9626, 710.3531, 753.6843], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [1126 1103   21]\n",
      "KL div tensor([-262.3538, -237.1506, -251.5943], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[  8/100] train_loss: 0.251 valid_loss: 659.016 valid_F1: 0.423 valid_AUC: 0.864 valid_Feature_p: 0.005 valid_MIFD: 0.479 valid_Silhouette: -0.010 Complexity Term: 0.000\n",
      "Epoch: 08 | Loss: 50.978 | KM Loss: 325.458 | Classification Loss: 194.911 | Cluster Balance Loss: 0.781\n",
      "Epoch: 09 | Loss: 62.024 | KM Loss: 310.896 | Classification Loss: 181.477 | Cluster Balance Loss: 0.866\n",
      "qval tensor([771.0192, 751.5240, 727.4568], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [1127 1119    4]\n",
      "KL div tensor([-257.3726, -250.8742, -242.8518], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[ 10/100] train_loss: 0.229 valid_loss: 668.491 valid_F1: 0.529 valid_AUC: 0.862 valid_Feature_p: 0.000 valid_MIFD: 0.292 valid_Silhouette: -0.046 Complexity Term: 0.000\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 10 | Loss: 56.480 | KM Loss: 293.917 | Classification Loss: 171.904 | Cluster Balance Loss: 0.900\n",
      "Epoch: 11 | Loss: 44.261 | KM Loss: 273.378 | Classification Loss: 162.243 | Cluster Balance Loss: 1.048\n",
      "qval tensor([785.1946, 728.7762, 736.0292], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [1339  901   10]\n",
      "KL div tensor([-262.0977, -243.2916, -245.7093], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[ 12/100] train_loss: 0.187 valid_loss: 703.427 valid_F1: 0.500 valid_AUC: 0.856 valid_Feature_p: 0.002 valid_MIFD: 0.369 valid_Silhouette: -0.053 Complexity Term: 0.000\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 12 | Loss: 46.625 | KM Loss: 250.796 | Classification Loss: 146.353 | Cluster Balance Loss: 0.940\n",
      "Epoch: 13 | Loss: 49.374 | KM Loss: 274.633 | Classification Loss: 160.289 | Cluster Balance Loss: 1.297\n",
      "qval tensor([765.8663, 743.2722, 740.8613], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [ 974 1220   56]\n",
      "KL div tensor([-255.6550, -248.1236, -247.3200], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[ 14/100] train_loss: 0.357 valid_loss: 829.803 valid_F1: 0.342 valid_AUC: 0.795 valid_Feature_p: 0.002 valid_MIFD: 0.482 valid_Silhouette: 0.100 Complexity Term: 0.000\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch: 14 | Loss: 53.560 | KM Loss: 316.293 | Classification Loss: 185.603 | Cluster Balance Loss: 1.082\n",
      "Epoch: 15 | Loss: 33.650 | KM Loss: 218.831 | Classification Loss: 128.138 | Cluster Balance Loss: 1.106\n",
      "qval tensor([760.5226, 780.2179, 709.2594], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [ 928 1320    2]\n",
      "KL div tensor([-253.8738, -260.4388, -236.7860], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[ 16/100] train_loss: 0.163 valid_loss: 830.579 valid_F1: 0.441 valid_AUC: 0.838 valid_Feature_p: 0.000 valid_MIFD: 0.223 valid_Silhouette: -0.111 Complexity Term: 0.000\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch: 16 | Loss: 34.017 | KM Loss: 202.301 | Classification Loss: 117.654 | Cluster Balance Loss: 0.781\n",
      "Epoch: 17 | Loss: 34.669 | KM Loss: 184.299 | Classification Loss: 105.622 | Cluster Balance Loss: 0.753\n",
      "qval tensor([778.3379, 741.8718, 729.7902], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [1263  982    5]\n",
      "KL div tensor([-259.8122, -247.6568, -243.6296], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[ 18/100] train_loss: 0.120 valid_loss: 926.220 valid_F1: 0.493 valid_AUC: 0.843 valid_Feature_p: 0.006 valid_MIFD: 0.295 valid_Silhouette: -0.126 Complexity Term: 0.000\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch: 18 | Loss: 36.329 | KM Loss: 161.703 | Classification Loss: 90.099 | Cluster Balance Loss: 0.760\n",
      "Epoch: 19 | Loss: 33.108 | KM Loss: 153.024 | Classification Loss: 85.227 | Cluster Balance Loss: 1.031\n",
      "qval tensor([746.4587, 804.2858, 699.2555], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [ 816 1428    6]\n",
      "KL div tensor([-249.1858, -268.4615, -233.4514], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[ 20/100] train_loss: 0.092 valid_loss: 1022.278 valid_F1: 0.473 valid_AUC: 0.827 valid_Feature_p: 0.001 valid_MIFD: 0.311 valid_Silhouette: -0.103 Complexity Term: 0.000\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch: 20 | Loss: 40.530 | KM Loss: 146.233 | Classification Loss: 78.199 | Cluster Balance Loss: 0.954\n",
      "Epoch: 21 | Loss: 35.938 | KM Loss: 130.449 | Classification Loss: 69.270 | Cluster Balance Loss: 0.887\n",
      "qval tensor([779.3241, 751.0248, 719.6512], grad_fn=<SumBackward1>)\n",
      "Cluster Counts [1205 1041    4]\n",
      "KL div tensor([-260.1409, -250.7078, -240.2500], grad_fn=<KlDivBackward>)\n",
      "\n",
      "[ 22/100] train_loss: 0.073 valid_loss: 1245.857 valid_F1: 0.451 valid_AUC: 0.817 valid_Feature_p: 0.038 valid_MIFD: 0.314 valid_Silhouette: -0.031 Complexity Term: 0.000\n",
      "EarlyStopping counter: 7 out of 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training\")\n",
    "model.train()\n",
    "N_EPOCHS = args.n_epochs\n",
    "es = EarlyStoppingCAC(dataset=suffix)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # beta = args.beta*(epoch*0.1)/(1+epoch*0.1)\n",
    "    beta = args.beta\n",
    "    # gamma = args.gamma - args.gamma*(epoch*0.1)/(1+epoch*0.1)\n",
    "    gamma = args.gamma\n",
    "    delta = args.delta\n",
    "    eta = args.eta\n",
    "    if epoch % args.log_interval == 0:\n",
    "        # plot(model, torch.FloatTensor(X_val).to(args.device), y_val, labels=None)\n",
    "        model.ae.eval() # prep model for evaluation\n",
    "        for j in range(model.n_clusters):\n",
    "            model.classifiers[j][0].eval()\n",
    "\n",
    "        z_train, _, q_train = model(torch.Tensor(X_train).to(args.device), output=\"decoded\")\n",
    "        q_train, q_train_p, q_train_n = q_train\n",
    "\n",
    "        # evaluate clustering performance\n",
    "        cluster_indices = q_train.detach().cpu().numpy().argmax(1)\n",
    "        preds = torch.zeros((len(z_train), 2))\n",
    "\n",
    "        # Calculate Training Metrics\n",
    "        nmi, acc, ari = 0, 0, 0\n",
    "        train_loss = 0\n",
    "        B = []\n",
    "\n",
    "        for j in range(model.n_clusters):\n",
    "            cluster_idx = np.where(cluster_indices == j)[0]\n",
    "            X_cluster = z_train[cluster_idx]\n",
    "            y_cluster = torch.Tensor(y_train[cluster_idx]).type(torch.LongTensor).to(model.device)\n",
    "\n",
    "            # B.append(torch.max(torch.linalg.norm(X_cluster, axis=1), axis=0).values)\n",
    "            cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "            train_loss += torch.sum(criterion(cluster_preds, y_cluster))\n",
    "\n",
    "        train_loss /= len(z_train)\n",
    "        # Evaluate model on Validation dataset\n",
    "        qs, z_val = model(torch.FloatTensor(X_val).to(args.device), output=\"latent\")\n",
    "        q_val = qs[0]\n",
    "        cluster_ids = torch.argmax(q_val, axis=1)\n",
    "        preds = torch.zeros((len(z_val), 2))\n",
    "\n",
    "        # Weighted predictions\n",
    "        if args.attention == False:\n",
    "            for j in range(model.n_clusters):\n",
    "                cluster_id = np.where(cluster_ids == j)[0]\n",
    "                X_cluster = z_val[cluster_id]\n",
    "                cluster_preds_val = model.classifiers[j][0](X_cluster)\n",
    "                preds[cluster_id,:] = cluster_preds_val\n",
    "\n",
    "        else:\n",
    "            for j in range(model.n_clusters):\n",
    "                X_cluster = z_val\n",
    "                cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "                preds[:,0] += q_val[:,j]*cluster_preds[:,0]\n",
    "                preds[:,1] += q_val[:,j]*cluster_preds[:,1]\n",
    "\n",
    "        print(\"qval\", torch.sum(q_val, axis=0))\n",
    "        print(\"Cluster Counts\", np.bincount(cluster_ids))\n",
    "        print(\"KL div\", torch.kl_div(torch.sum(q_val, axis=0),\\\n",
    "                                torch.ones(args.n_clusters)/args.n_clusters))\n",
    "\n",
    "        # Classification Matrics\n",
    "        val_f1  = f1_score(y_val, np.argmax(preds.detach().numpy(), axis=1))\n",
    "        val_auc = roc_auc_score(y_val, preds[:,1].detach().numpy())\n",
    "\n",
    "        # Clustering Metrics\n",
    "        val_sil = silhouette_new(z_val.data.cpu().numpy(), cluster_ids.data.cpu().numpy(), metric='euclidean')\n",
    "        val_feature_diff = calculate_nhfd(X_val, cluster_ids)\n",
    "        val_MIFD = calculate_MIFD(X_val, cluster_ids)\n",
    "        complexity_term = 0\n",
    "        # complexity_term  = calculate_bound(model, B, len(z_train))\n",
    "\n",
    "        val_loss = torch.mean(criterion(preds, torch.Tensor(y_val).type(torch.LongTensor)))\n",
    "\n",
    "        # # record validation loss\n",
    "        # valid_losses.append(loss.item())\n",
    "\n",
    "        # # calculate average loss over an epoch\n",
    "        # valid_loss = np.average(valid_losses)\n",
    "        # avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        epoch_len = len(str(N_EPOCHS))\n",
    "\n",
    "        print_msg = (f'\\n[{epoch:>{epoch_len}}/{N_EPOCHS:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.3f} ' +\n",
    "                     f'valid_loss: {val_loss:.3f} '  +\n",
    "                     f'valid_F1: {val_f1:.3f} '  +\n",
    "                     f'valid_AUC: {val_auc:.3f} ' + \n",
    "                     f'valid_Feature_p: {val_feature_diff:.3f} ' + \n",
    "                     f'valid_MIFD: {val_MIFD:.3f} ' + \n",
    "                     f'valid_Silhouette: {val_sil:.3f} ' + \n",
    "                     f'Complexity Term: {complexity_term:.3f}')\n",
    "\n",
    "        print(print_msg)\n",
    "\n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        es([val_f1, val_auc], model)\n",
    "        if es.early_stop == True:\n",
    "            break\n",
    "\n",
    "    # Normal Training\n",
    "    epoch_loss = 0\n",
    "    epoch_balance_loss = 0\n",
    "    epoch_class_loss = 0\n",
    "    epoch_km_loss = 0\n",
    "\n",
    "    model.ae.train() # prep model for evaluation\n",
    "    for j in range(model.n_clusters):\n",
    "        model.classifiers[j][0].train()\n",
    "\n",
    "    for batch_idx, (x_batch, y_batch, idx) in enumerate(train_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        idx = idx.to(device)\n",
    "\n",
    "        X_latents, x_bar, q_batch = model(x_batch)\n",
    "        q_batch = q_batch[0]\n",
    "        reconstr_loss = F.mse_loss(x_bar, x_batch)\n",
    "\n",
    "        classifier_labels = np.zeros(len(idx))\n",
    "        sub_epochs = min(10, 1 + int(epoch/5))\n",
    "\n",
    "        if args.attention == False:\n",
    "            classifier_labels = np.argmax(q_batch.detach().cpu().numpy(), axis=1)\n",
    "\n",
    "        for _ in range(sub_epochs):\n",
    "            # Choose classifier for a point probabilistically\n",
    "            if args.attention == True:\n",
    "                for j in range(len(idx)):\n",
    "                    classifier_labels[j] = np.random.choice(range(args.n_clusters), p = q_batch[j].detach().numpy())\n",
    "\n",
    "            for k in range(args.n_clusters):\n",
    "                idx_cluster = np.where(classifier_labels == k)[0]\n",
    "                X_cluster = X_latents[idx_cluster]\n",
    "                y_cluster = y_batch[idx_cluster]\n",
    "\n",
    "                classifier_k, optimizer_k = model.classifiers[k]\n",
    "                # Do not backprop the error to encoder\n",
    "                y_pred_cluster = classifier_k(X_cluster.detach())\n",
    "                cluster_loss = torch.mean(criterion(y_pred_cluster, y_cluster))\n",
    "                optimizer_k.zero_grad()\n",
    "                cluster_loss.backward(retain_graph=True)\n",
    "                optimizer_k.step()\n",
    "\n",
    "        # Back propagate the error corresponding to last clustering\n",
    "        class_loss = torch.tensor(0.).to(args.device)\n",
    "        for k in range(args.n_clusters):\n",
    "            idx_cluster = np.where(classifier_labels == k)[0]\n",
    "            X_cluster = X_latents[idx_cluster]\n",
    "            y_cluster = y_batch[idx_cluster]\n",
    "\n",
    "            classifier_k, optimizer_k = model.classifiers[k]\n",
    "            y_pred_cluster = classifier_k(X_cluster)\n",
    "            class_loss += torch.sum(q_batch[idx_cluster,k]*criterion(y_pred_cluster, y_cluster))\n",
    "\n",
    "        class_loss /= len(X_latents)\n",
    "        delta_mu   = torch.zeros((args.n_clusters, args.latent_dim)).to(args.device)\n",
    "        delta_mu_p = torch.zeros((args.n_clusters, args.latent_dim)).to(args.device)\n",
    "        delta_mu_n = torch.zeros((args.n_clusters, args.latent_dim)).to(args.device)\n",
    "\n",
    "        cluster_id = torch.argmax(q_batch, 1)\n",
    "        # print(np.bincount(cluster_id.cpu().numpy()))\n",
    "\n",
    "        positive_class_dist = 0\n",
    "        negative_class_dist = 0\n",
    "        km_loss             = 0\n",
    "        class_sep_loss      = 0\n",
    "\n",
    "        for j in range(args.n_clusters):\n",
    "            pts_index = np.where(cluster_id == j)[0]\n",
    "            cluster_pts = X_latents[pts_index]\n",
    "            n_class_index = np.where(y_batch[pts_index] == 0)[0]\n",
    "            p_class_index = np.where(y_batch[pts_index] == 1)[0]\n",
    "\n",
    "            n_class = cluster_pts[n_class_index]\n",
    "            p_class = cluster_pts[p_class_index]\n",
    "\n",
    "            delta_mu_p[j,:] = p_class.sum(axis=0)/(1+len(p_class))\n",
    "            delta_mu_n[j,:] = n_class.sum(axis=0)/(1+len(n_class))\n",
    "            delta_mu[j,:]   = cluster_pts.sum(axis=0)/(1+len(cluster_pts))\n",
    "\n",
    "            s1 = torch.linalg.vector_norm(X_latents[p_class_index] - model.p_cluster_layer[j])/(1+len(p_class))\n",
    "            s2 = torch.linalg.vector_norm(X_latents[n_class_index] - model.n_cluster_layer[j])/(1+len(n_class))\n",
    "            m12 = torch.linalg.vector_norm(model.p_cluster_layer[j] - model.n_cluster_layer[j])\n",
    "\n",
    "            class_sep_loss += (s1+s2)/m12\n",
    "            km_loss += torch.linalg.vector_norm(X_latents[pts_index] - model.cluster_layer[j])/(1+len(cluster_pts))\n",
    "\n",
    "        q_batch = source_distribution(X_latents, model.cluster_layer, alpha=model.alpha)\n",
    "        P = torch.sum(torch.nn.Softmax(dim=1)(10*q_batch), axis=0)\n",
    "        P = P/P.sum()\n",
    "        Q = torch.ones(args.n_clusters)/args.n_clusters # Uniform distribution\n",
    "\n",
    "        if args.cluster_balance == \"kl\":\n",
    "            cluster_balance_loss = F.kl_div(P.log(), Q, reduction='batchmean')\n",
    "        else:\n",
    "            cluster_balance_loss = torch.linalg.vector_norm(torch.sqrt(P) - torch.sqrt(Q))\n",
    "\n",
    "        loss = reconstr_loss\n",
    "        if args.beta != 0:\n",
    "            loss += beta*km_loss\n",
    "        if args.gamma != 0:\n",
    "            loss += gamma*class_loss\n",
    "        if args.delta != 0:\n",
    "            loss += delta*cluster_balance_loss\n",
    "        if args.eta != 0:\n",
    "            loss += eta*class_sep_loss\n",
    "\n",
    "        epoch_loss += loss\n",
    "        epoch_class_loss += class_loss\n",
    "        epoch_balance_loss += cluster_balance_loss\n",
    "        epoch_km_loss += km_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the positive and negative centroids\n",
    "        for j in range(args.n_clusters):\n",
    "            pts_index = np.where(cluster_id == j)[0]\n",
    "            n_class_index = np.where(y[pts_index] == 0)[0]\n",
    "            p_class_index = np.where(y[pts_index] == 1)[0]\n",
    "\n",
    "            N  = len(pts_index)\n",
    "            Np = len(p_class_index)\n",
    "            Nn = len(n_class_index)\n",
    "            model.p_cluster_layer.data[j:] -= (1/(100+Np))*delta_mu_p[j:]\n",
    "            model.n_cluster_layer.data[j:] -= (1/(100+Nn))*delta_mu_n[j:]\n",
    "            model.cluster_layer.data[j:]   -= (1/(100+N))*delta_mu[j:]\n",
    "\n",
    "    print('Epoch: {:02d} | Loss: {:.3f} | KM Loss: {:.3f} | Classification Loss: {:.3f} | Cluster Balance Loss: {:.3f}'.format(\n",
    "                epoch, epoch_km_loss, epoch_loss, epoch_class_loss, epoch_balance_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIFD Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========\n",
      "\n",
      "1,0\n",
      "{'Mg_first': 1.139, 'TroponinT_first': 1.081, 'AST_first': 1.0, 'CCU': 0.986, 'ALT_last': 0.983, 'TroponinI_first': 0.962, 'AST_last': 0.933, 'TroponinI_last': 0.853, 'ALP_last': 0.84, 'TroponinT_last': 0.821}\n",
      "\n",
      "========\n",
      "\n",
      "2,0\n",
      "{'CCU': 0.834, 'CSRU': 0.764, 'SICU': 0.727, 'MechVentLast8Hour': 0.229, 'GCS_first': 0.182, 'GCS_highest': 0.177, 'SOFA': 0.148, 'FiO2_first': 0.142, 'HCO3_last': 0.142, 'PaO2_last': 0.138}\n",
      "\n",
      "========\n",
      "\n",
      "2,1\n",
      "{'CCU': 0.875, 'CSRU': 0.779, 'SICU': 0.715, 'MechVentLast8Hour': 0.274, 'GCS_first': 0.222, 'HCO3_last': 0.209, 'PaO2_last': 0.181, 'GCS_lowest': 0.165, 'GCS_highest': 0.14, 'HCT_last': 0.137}\n"
     ]
    }
   ],
   "source": [
    "cluster_entrpy = 0\n",
    "cntr = 0\n",
    "n_columns = X_train.shape[1]\n",
    "n_clusters = len(torch.unique(cluster_ids))\n",
    "input_dim = X_train.shape[1]\n",
    "mi_scores = {}\n",
    "for i in range(n_clusters):\n",
    "    for j in range(n_clusters):\n",
    "        if i > j:\n",
    "            joint_col_name = str(i) + \",\" + str(j)\n",
    "            mi_scores[joint_col_name] = {}\n",
    "            ci = torch.where(cluster_ids == i)[0]\n",
    "            cj = torch.where(cluster_ids == j)[0]\n",
    "            Xi = X_train[ci]\n",
    "            Xj = X_train[cj]\n",
    "            col_entrpy = 0\n",
    "            for c in range(n_columns):\n",
    "                c_entropy = calc_MI(Xi[:,c], Xj[:,c], 0)\n",
    "                col_entrpy += c_entropy\n",
    "                mi_scores[joint_col_name][column_names[c]] = np.round(c_entropy, 3)\n",
    "                # print(column_names[c], \":\", c_entropy)\n",
    "            cluster_entrpy += col_entrpy/n_columns\n",
    "            cntr += 1\n",
    "            print(\"\\n========\\n\")\n",
    "            print(joint_col_name)\n",
    "            sorted_dict = sorted(mi_scores[joint_col_name].items(), key=lambda item: -item[1])[:10]\n",
    "            print({k: v for k, v in sorted_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========\n",
      "\n",
      "1,0\n",
      "{'AST_last': 1.0, 'MAP_last': 0.995, 'NIDiasABP_highest': 0.99, 'GCS_highest': 0.986, 'FiO2_last': 0.982, 'NISysABP_highest': 0.979, 'NIMAP_highest': 0.899, 'Platelets_first': 0.894, 'WBC_first': 0.892, 'Lactate_first': 0.891}\n",
      "\n",
      "========\n",
      "\n",
      "2,0\n",
      "{'TroponinI_last': 0.993, 'TroponinI_first': 0.992, 'SaO2_lowest': 0.981, 'RespRate_median': 0.981, 'FiO2_last': 0.969, 'pH_last': 0.969, 'RespRate_first': 0.966, 'RespRate_lowest': 0.963, 'RespRate_last': 0.954, 'DiasABP_lowest': 0.949}\n",
      "\n",
      "========\n",
      "\n",
      "2,1\n",
      "{'Height': 0.994, 'RespRate_median': 0.98, 'FiO2_last': 0.972, 'DiasABP_median': 0.971, 'TroponinI_last': 0.966, 'SaO2_lowest': 0.965, 'Na_first': 0.957, 'pH_last': 0.953, 'RespRate_highest': 0.949, 'TroponinI_first': 0.949}\n"
     ]
    }
   ],
   "source": [
    "cluster_entrpy = 0\n",
    "cntr = 0\n",
    "n_columns = X_train.shape[1]\n",
    "n_clusters = len(torch.unique(cluster_ids))\n",
    "input_dim = X_train.shape[1]\n",
    "mi_scores = {}\n",
    "for i in range(n_clusters):\n",
    "    for j in range(n_clusters):\n",
    "        if i > j:\n",
    "            joint_col_name = str(i) + \",\" + str(j)\n",
    "            mi_scores[joint_col_name] = {}\n",
    "            ci = torch.where(cluster_ids == i)[0]\n",
    "            cj = torch.where(cluster_ids == j)[0]\n",
    "            Xi = X_train[ci]\n",
    "            Xj = X_train[cj]\n",
    "            col_entrpy = 0\n",
    "            p_vals = np.nan_to_num(ttest_ind(Xi, Xj, axis=0))[1]\n",
    "            for c in range(n_columns):\n",
    "                mi_scores[joint_col_name][column_names[c]] = np.round(p_vals[c], 3)\n",
    "                # print(column_names[c], \":\", c_entropy)\n",
    "            cntr += 1\n",
    "            print(\"\\n========\\n\")\n",
    "            print(joint_col_name)\n",
    "            sorted_dict = sorted(mi_scores[joint_col_name].items(), key=lambda item: -item[1])[:10]\n",
    "            print({k: v for k, v in sorted_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################\n",
      "\n",
      "Training Local Networks\n",
      "Loading Best model with score:  [0.4225352112676057, 0.8639392607392608]\n",
      "\n",
      "[ 22/100] train_loss: 306.277 valid_loss: 664.194 valid_F1: 0.469 valid_AUC: 0.865 valid_Sil: -0.010\n",
      "\n",
      "[ 22/100] train_loss: 304.992 valid_loss: 671.371 valid_F1: 0.478 valid_AUC: 0.865 valid_Sil: -0.010\n",
      "\n",
      "[ 22/100] train_loss: 304.820 valid_loss: 663.208 valid_F1: 0.470 valid_AUC: 0.865 valid_Sil: -0.010\n",
      "\n",
      "[ 22/100] train_loss: 304.220 valid_loss: 662.152 valid_F1: 0.474 valid_AUC: 0.865 valid_Sil: -0.010\n",
      "\n",
      "[ 22/100] train_loss: 303.008 valid_loss: 662.822 valid_F1: 0.480 valid_AUC: 0.865 valid_Sil: -0.010\n",
      "\n",
      "[ 22/100] train_loss: 302.547 valid_loss: 663.330 valid_F1: 0.470 valid_AUC: 0.866 valid_Sil: -0.010\n",
      "\n",
      "[ 22/100] train_loss: 302.707 valid_loss: 662.718 valid_F1: 0.484 valid_AUC: 0.866 valid_Sil: -0.010\n",
      "\n",
      "[ 22/100] train_loss: 302.382 valid_loss: 663.487 valid_F1: 0.480 valid_AUC: 0.866 valid_Sil: -0.010\n",
      "EarlyStopping counter: 1 out of 7\n",
      "\n",
      "[ 22/100] train_loss: 303.137 valid_loss: 660.735 valid_F1: 0.486 valid_AUC: 0.866 valid_Sil: -0.010\n",
      "EarlyStopping counter: 2 out of 7\n",
      "\n",
      "[ 22/100] train_loss: 301.904 valid_loss: 660.259 valid_F1: 0.471 valid_AUC: 0.866 valid_Sil: -0.010\n",
      "EarlyStopping counter: 3 out of 7\n",
      "\n",
      "[ 22/100] train_loss: 301.938 valid_loss: 660.745 valid_F1: 0.477 valid_AUC: 0.866 valid_Sil: -0.010\n",
      "EarlyStopping counter: 4 out of 7\n",
      "\n",
      "[ 22/100] train_loss: 302.301 valid_loss: 662.880 valid_F1: 0.477 valid_AUC: 0.866 valid_Sil: -0.010\n",
      "EarlyStopping counter: 5 out of 7\n",
      "\n",
      "[ 22/100] train_loss: 301.251 valid_loss: 662.012 valid_F1: 0.469 valid_AUC: 0.865 valid_Sil: -0.010\n",
      "EarlyStopping counter: 6 out of 7\n",
      "\n",
      "[ 22/100] train_loss: 300.914 valid_loss: 662.513 valid_F1: 0.473 valid_AUC: 0.865 valid_Sil: -0.010\n",
      "EarlyStopping counter: 7 out of 7\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n####################################################################################\\n\")\n",
    "print(\"Training Local Networks\")\n",
    "model = es.load_checkpoint(model)\n",
    "\n",
    "es = EarlyStoppingCAC(dataset=suffix)\n",
    "\n",
    "qs, z_train = model(torch.FloatTensor(np.array(X_train)).to(args.device), output=\"latent\")\n",
    "q_train = qs[0]\n",
    "cluster_id_train = torch.argmax(q_train, axis=1)\n",
    "\n",
    "# X_latents_data_loader = list(zip(z_train, cluster_id_train, y_train))\n",
    "X_latents_data_loader = list(zip(z_train.to(args.device),q_train, y_train))\n",
    "\n",
    "train_loader_latents = torch.utils.data.DataLoader(X_latents_data_loader,\n",
    "    batch_size=1024, shuffle=False)\n",
    "\n",
    "B = []\n",
    "\n",
    "# plot(model, torch.FloatTensor(np.array(X_train)).to(args.device), y_train,\\\n",
    "#      torch.FloatTensor(np.array(X_test)).to(args.device), y_test)\n",
    "\n",
    "# Post clustering training\n",
    "for e in range(N_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1 = 0\n",
    "    acc = 0\n",
    "\n",
    "    # model.ae.train() # prep model for evaluation\n",
    "    for j in range(model.n_clusters):\n",
    "        model.classifiers[j][0].train()\n",
    "\n",
    "    # Full training of local networks\n",
    "    for batch_idx, (X_latents, q_batch, y_batch) in enumerate(train_loader_latents):\n",
    "        # torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "        classifier_labels = np.zeros(len(X_latents))\n",
    "        # Choose classifier for a point probabilistically\n",
    "        if args.attention == True:\n",
    "            for j in range(len(X_latents)):\n",
    "                classifier_labels[j] = np.random.choice(range(args.n_clusters), p = q_batch[j].detach().numpy())\n",
    "        else:\n",
    "            classifier_labels = torch.argmax(q_batch, axis=1).data.cpu().numpy()\n",
    "\n",
    "        for k in range(args.n_clusters):\n",
    "            idx_cluster = np.where(classifier_labels == k)[0]\n",
    "            X_cluster = X_latents[idx_cluster]\n",
    "            y_cluster = y_batch[idx_cluster]\n",
    "\n",
    "            classifier_k, optimizer_k = model.classifiers[k]\n",
    "            # Do not backprop the error to encoder\n",
    "            y_pred_cluster = classifier_k(X_cluster.detach())\n",
    "            cluster_loss = torch.mean(criterion(y_pred_cluster, y_cluster))\n",
    "            optimizer_k.zero_grad()\n",
    "            cluster_loss.backward(retain_graph=True)\n",
    "            optimizer_k.step()\n",
    "\n",
    "    # model.ae.eval() # prep model for evaluation\n",
    "    for j in range(model.n_clusters):\n",
    "        model.classifiers[j][0].eval()\n",
    "\n",
    "    train_preds = torch.zeros((len(z_train), 2))\n",
    "    train_loss = 0\n",
    "\n",
    "    # Weighted predictions\n",
    "    q_train, z_train = model(torch.FloatTensor(X_train).to(args.device), output=\"latent\")\n",
    "    q_train = q_train[0]\n",
    "    cluster_ids_train = torch.argmax(q_train, axis=1)\n",
    "\n",
    "    for j in range(model.n_clusters):\n",
    "        cluster_id = np.where(cluster_ids_train == j)[0]\n",
    "        X_cluster = z_train\n",
    "        y_cluster = torch.Tensor(y_train[cluster_id]).type(torch.LongTensor)\n",
    "\n",
    "        # Ensemble train loss\n",
    "        cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "        train_preds[:,0] += q_train[:,j]*cluster_preds[:,0]\n",
    "        train_preds[:,1] += q_train[:,j]*cluster_preds[:,1]\n",
    "\n",
    "        X_cluster = z_train[cluster_id]\n",
    "        cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "        train_loss += torch.sum(q_train[cluster_id,j]*criterion(cluster_preds, y_cluster))\n",
    "        # B.append(torch.max(torch.linalg.norm(X_cluster, axis=1), axis=0).values)\n",
    "\n",
    "\n",
    "    train_loss /= len(z_train)\n",
    "    e_train_loss = torch.mean(criterion(train_preds, torch.Tensor(y_train).type(torch.LongTensor)))\n",
    "\n",
    "    # Evaluate model on Validation set\n",
    "    qs, z_val = model(torch.FloatTensor(X_val).to(args.device), output=\"latent\")\n",
    "    q_val = qs[0]\n",
    "    cluster_ids_val = torch.argmax(q_val, axis=1)\n",
    "    preds = torch.zeros((len(z_val), 2))\n",
    "\n",
    "    # Weighted predictions\n",
    "    for j in range(model.n_clusters):\n",
    "        cluster_id = np.where(cluster_ids_val == j)[0]\n",
    "        X_cluster = z_val\n",
    "        cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "        preds[:,0] += q_val[:,j]*cluster_preds[:,0]\n",
    "        preds[:,1] += q_val[:,j]*cluster_preds[:,1]\n",
    "\n",
    "    val_f1  = f1_score(y_val, np.argmax(preds.detach().numpy(), axis=1))\n",
    "    val_auc = roc_auc_score(y_val, preds[:,1].detach().numpy())\n",
    "    val_sil = silhouette_new(z_val.data.cpu().numpy(), cluster_ids_val.data.cpu().numpy(), metric='euclidean')\n",
    "\n",
    "    val_loss = torch.mean(criterion(preds, torch.Tensor(y_val).type(torch.LongTensor)))\n",
    "    # record validation loss\n",
    "    # valid_losses.append(loss.item())\n",
    "\n",
    "    # calculate average loss over an epoch\n",
    "    # valid_loss = np.average(valid_losses)\n",
    "    # avg_valid_losses.append(valid_loss)\n",
    "\n",
    "    epoch_len = len(str(N_EPOCHS))\n",
    "\n",
    "    print_msg = (f'\\n[{epoch:>{epoch_len}}/{N_EPOCHS:>{epoch_len}}] ' +\n",
    "                 f'train_loss: {train_loss:.3f} ' +\n",
    "                 f'valid_loss: {val_loss:.3f} '  +\n",
    "                 f'valid_F1: {val_f1:.3f} '  +\n",
    "                 f'valid_AUC: {val_auc:.3f} ' +\n",
    "                 f'valid_Sil: {val_sil:.3f}')\n",
    "\n",
    "    print(print_msg)\n",
    "\n",
    "    # early_stopping needs the validation loss to check if it has decresed, \n",
    "    # and if it has, it will make a checkpoint of the current model\n",
    "    es([val_f1, val_auc], model)\n",
    "    if es.early_stop == True:\n",
    "        train_losses.append(train_loss.item())\n",
    "        e_train_losses.append(e_train_loss.item())\n",
    "        sil_scores.append(silhouette_new(z_train.data.cpu().numpy(), cluster_ids_train.data.cpu().numpy(), metric='euclidean'))\n",
    "        nhfd_scores.append(calculate_nhfd(X_train,  cluster_ids_train))\n",
    "        mifd_scores.append(calculate_MIFD(X_train,  cluster_ids_train))\n",
    "        # model_complexity.append(calculate_bound(model, B, len(z_train)))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################\n",
      "\n",
      "Evaluating Test Data with k =  3  Attention =  True\n",
      "Loading Best model with score:  [0.5, 0.8614633366633366]\n",
      "Loss Metrics - Test Loss 939.536, E-Test Loss 946.010, Local Sum Test Loss 122.919\n",
      "Clustering Metrics     - Acc 0.0000 , nmi 0.0000 , ari 0.0000, NHFD 0.074\n",
      "Classification Metrics - Test F1 0.438, Test AUC 0.847, Test ACC 0.869 , E-Test F1 0.466, E-Test AUC 0.855, E-Test ACC 0.872\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test F1:  [0.46582984658298465]\n",
      "Test AUC:  [0.855149271086176]\n",
      "Sil scores:  [-0.01068612]\n",
      "NHFD:  [0.3387557710957288]\n",
      "MIFD:  [1.1413843291757655]\n",
      "Train Loss:  [190.31500244140625]\n",
      "E-Train Loss:  [1446.4432373046875]\n",
      "Test Loss:  [939.5361328125]\n",
      "E-Test Loss:  [946.0103149414062]\n",
      "Local Test Loss:  [122.91876983642578]\n",
      "Model Complexity:  []\n",
      "Dataset\tk\tF1\tAUC\tACC\tSIL\tNHFD\tMIFD\tW-NHFD\n",
      "cic\t3\t0.466\t0.855\tnan\t-0.011\t0.339\t1.141\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivin/miniconda/lib/python3.8/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/Users/shivin/miniconda/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n####################################################################################\\n\")\n",
    "print(\"Evaluating Test Data with k = \", args.n_clusters, \" Attention = \", args.attention)\n",
    "\n",
    "# Load best model trained from local training phase\n",
    "model = es.load_checkpoint(model)\n",
    "\n",
    "# # Evaluate model on Test dataset\n",
    "qs, z_test = model(torch.FloatTensor(X_test).to(args.device), output=\"latent\")\n",
    "q_test = qs[0]\n",
    "cluster_ids = torch.argmax(q_test, axis=1)\n",
    "# cluster_ids = np.argmax(distance_matrix(z_test.data.cpu().numpy(), model.cluster_layer.data.cpu().numpy()), axis=1)\n",
    "test_preds_e = torch.zeros((len(z_test), 2))\n",
    "\n",
    "test_loss = 0\n",
    "e_test_loss = 0\n",
    "local_sum_loss = 0\n",
    "\n",
    "# Weighted predictions\n",
    "for j in range(model.n_clusters):\n",
    "    cluster_id = np.where(cluster_ids == j)[0]\n",
    "    X_cluster = z_test\n",
    "    cluster_test_preds = model.classifiers[j][0](X_cluster)\n",
    "    test_preds_e[:,0] += q_test[:,j]*cluster_test_preds[:,0]\n",
    "    test_preds_e[:,1] += q_test[:,j]*cluster_test_preds[:,1]\n",
    "\n",
    "e_test_loss = torch.mean(criterion(test_preds_e, torch.Tensor(y_test).type(torch.LongTensor)))\n",
    "e_test_f1 = f1_score(y_test, np.argmax(test_preds_e.detach().numpy(), axis=1))\n",
    "e_test_auc = roc_auc_score(y_test, test_preds_e[:,1].detach().numpy())\n",
    "e_test_acc = accuracy_score(y_test, np.argmax(test_preds_e.detach().numpy(), axis=1))\n",
    "e_test_nhfd = calculate_nhfd(X_test, cluster_ids)\n",
    "\n",
    "test_preds = torch.zeros((len(z_test), 2))\n",
    "\n",
    "# Hard local predictions\n",
    "for j in range(model.n_clusters):\n",
    "    cluster_id = np.where(cluster_ids == j)[0]\n",
    "    X_cluster = z_test[cluster_id]\n",
    "    y_cluster = torch.Tensor(y_test[cluster_id]).type(torch.LongTensor)\n",
    "    cluster_test_preds = model.classifiers[j][0](X_cluster)\n",
    "    test_preds[cluster_id,:] = cluster_test_preds\n",
    "    local_sum_loss += torch.sum(q_test[cluster_id,j]*criterion(cluster_test_preds, y_cluster))\n",
    "\n",
    "test_f1 = f1_score(y_test, np.argmax(test_preds.detach().numpy(), axis=1))\n",
    "test_auc = roc_auc_score(y_test, test_preds[:,1].detach().numpy())\n",
    "test_acc = accuracy_score(y_test, np.argmax(test_preds.detach().numpy(), axis=1))\n",
    "test_loss = torch.mean(criterion(test_preds, torch.Tensor(y_test).type(torch.LongTensor)))\n",
    "local_sum_loss /= len(X_test)\n",
    "\n",
    "test_losses.append(test_loss.item())\n",
    "e_test_losses.append(e_test_loss.item())\n",
    "local_sum_test_losses.append(local_sum_loss.item())\n",
    "\n",
    "# enablePrint()\n",
    "# print(\"Run #{}\".format(r))\n",
    "\n",
    "print('Loss Metrics - Test Loss {:.3f}, E-Test Loss {:.3f}, Local Sum Test Loss {:.3f}'.format(test_loss, e_test_loss, local_sum_loss))\n",
    "\n",
    "print('Clustering Metrics     - Acc {:.4f}'.format(acc), ', nmi {:.4f}'.format(nmi),\\\n",
    "      ', ari {:.4f}, NHFD {:.3f}'.format(ari, e_test_nhfd))\n",
    "\n",
    "print('Classification Metrics - Test F1 {:.3f}, Test AUC {:.3f}, Test ACC {:.3f}'.format(test_f1, test_auc, test_acc),\\\n",
    "    ', E-Test F1 {:.3f}, E-Test AUC {:.3f}, E-Test ACC {:.3f}'.format(e_test_f1, e_test_auc, e_test_acc))\n",
    "\n",
    "print(\"\\n\")\n",
    "f1_scores.append(e_test_f1)\n",
    "auc_scores.append(e_test_auc)\n",
    "# acc_scores.append(e_test_acc)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Test F1: \", f1_scores)\n",
    "print(\"Test AUC: \", auc_scores)\n",
    "\n",
    "print(\"Sil scores: \", sil_scores)\n",
    "print(\"NHFD: \", nhfd_scores)\n",
    "print(\"MIFD: \", mifd_scores)\n",
    "\n",
    "print(\"Train Loss: \", train_losses)\n",
    "print(\"E-Train Loss: \", e_train_losses)\n",
    "\n",
    "print(\"Test Loss: \", test_losses)\n",
    "print(\"E-Test Loss: \", e_test_losses)\n",
    "print(\"Local Test Loss: \", local_sum_test_losses)\n",
    "\n",
    "print(\"Model Complexity: \", model_complexity)\n",
    "\n",
    "# enablePrint()\n",
    "print(\"Dataset\\tk\\tF1\\tAUC\\tACC\\tSIL\\tNHFD\\tMIFD\\tW-NHFD\")\n",
    "\n",
    "print(\"{}\\t{}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\".format\\\n",
    "    (args.dataset, args.n_clusters, np.average(f1_scores), np.average(auc_scores),\\\n",
    "    np.average(acc_scores), np.average(sil_scores), np.average(nhfd_scores),\\\n",
    "    np.average(mifd_scores), np.average(w_nhfd_scores)))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means feature segregation ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score as ari_score\n",
    "km = KMeans(n_clusters=args.n_clusters, n_init=20)\n",
    "cluster_ids = torch.argmax(q_train, axis=1).data.cpu().numpy()\n",
    "n_features = X_train.shape[1]\n",
    "nmi_scores = {}\n",
    "ari_scores = {}\n",
    "nmi_sum = 0\n",
    "ari_sum = 0\n",
    "for feature in range(n_features):\n",
    "    feature_labels = km.fit(X_train[:,feature].reshape(-1,1)).labels_\n",
    "    nmi = nmi_score(feature_labels, cluster_ids)\n",
    "    ari = ari_score(feature_labels, cluster_ids)\n",
    "    nmi_sum += nmi\n",
    "    ari_sum += ari\n",
    "    nmi_scores[column_names[feature]] = np.round(nmi, 3)\n",
    "    ari_scores[column_names[feature]] = np.round(ari, 3)\n",
    "\n",
    "nmi_sum, ari_sum\n",
    "{k: v for k, v in sorted(nmi_scores.items(), key=lambda item: item[1])}\n",
    "{k: v for k, v in sorted(ari_scores.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_val, q_val)\n",
    "q_labels = torch.argmax(q_val, axis=1).data.cpu().numpy()\n",
    "km_labels = kmeans.fit_predict(z_val.data.cpu().numpy())\n",
    "print(km_labels)\n",
    "print(nmi_score(q_labels, km_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #  0 sized:  2522\n",
      "[('GCS_last', 0.253), ('Age', 0.145), ('BUN_first', 0.101), ('CSRU', 0.073), ('GCS_first', 0.06), ('RespRate_median', 0.043), ('BUN_last', 0.023), ('PaO2_first', 0.02), ('RespRate_highest', 0.017), ('HR_highest', 0.017)]\n",
      "=========================\n",
      "\n",
      "Cluster #  1 sized:  2258\n",
      "[('GCS_last', 0.236), ('Age', 0.116), ('BUN_last', 0.095), ('GCS_first', 0.079), ('PaO2_first', 0.042), ('CSRU', 0.037), ('RespRate_highest', 0.033), ('BUN_first', 0.025), ('FiO2_last', 0.023), ('HR_highest', 0.022)]\n",
      "=========================\n",
      "\n",
      "Cluster #  2 sized:  1970\n",
      "[('GCS_last', 0.29), ('BUN_last', 0.115), ('Age', 0.06), ('HCO3_last', 0.039), ('SAPS-I', 0.037), ('HR_highest', 0.034), ('CSRU', 0.034), ('Bilirubin_last', 0.033), ('BUN_first', 0.031), ('Glucose_last', 0.021)]\n",
      "=========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "################################### Feature Imp. ###################################\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "\n",
    "plot(model, torch.FloatTensor(X_train).to(args.device), y_train, labels=None)\n",
    "\n",
    "regs = [GradientBoostingRegressor(random_state=0) for _ in range(args.n_clusters)]\n",
    "qs, z_train = model(torch.FloatTensor(X_train).to(args.device), output=\"latent\")\n",
    "q_train = qs[0]\n",
    "cluster_ids = torch.argmax(q_train, axis=1)\n",
    "preds_e = torch.zeros((len(z_train), 2))\n",
    "feature_importances = np.zeros((args.n_clusters, args.input_dim))\n",
    "\n",
    "# Weighted predictions\n",
    "for j in range(model.n_clusters):\n",
    "    cluster_id = np.where(cluster_ids == j)[0]\n",
    "    # X_cluster = z_test[cluster_id]\n",
    "    X_cluster = z_train\n",
    "    cluster_preds = model.classifiers[j][0](X_cluster)\n",
    "    # print(q_test, cluster_preds[:,0])\n",
    "    preds_e[:,0] += q_train[:,j]*cluster_preds[:,0]\n",
    "    preds_e[:,1] += q_train[:,j]*cluster_preds[:,1]\n",
    "\n",
    "for j in range(model.n_clusters):\n",
    "    cluster_id = torch.where(cluster_ids == j)[0]\n",
    "    X_cluster = X_train[cluster_id]\n",
    "    if args.attention == True:\n",
    "        y_cluster = preds_e[cluster_id][:,1]\n",
    "    else:\n",
    "        y_cluster = preds[cluster_id][:,1]\n",
    "\n",
    "    # Some test data might not belong to any cluster\n",
    "    if len(cluster_id) > 0:\n",
    "        regs[j].fit(X_cluster, y_cluster.detach().cpu().numpy())\n",
    "        best_features = np.argsort(regs[j].feature_importances_)[::-1][:10]\n",
    "        feature_importances[j,:] = regs[j].feature_importances_\n",
    "        print(\"Cluster # \", j, \"sized: \", len(cluster_id))\n",
    "        print(list(zip(column_names[best_features], np.round(regs[j].feature_importances_[best_features], 3))))\n",
    "        print(\"=========================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "f1_scores, auc_scores = [], []\n",
    "\n",
    "for r in range(5):\n",
    "    m = NNClassifier(args, input_dim=89)\n",
    "    device = args.device\n",
    "\n",
    "    N_EPOCHS = args.n_epochs\n",
    "    es = EarlyStopping(dataset=args.dataset, path=\"./pretrained_model/checkpoint_base\")\n",
    "\n",
    "    kmeans = KMeans(n_clusters=args.n_classes, n_init=20)\n",
    "\n",
    "    for e in range(1, N_EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        epoch_f1 = 0\n",
    "        m.train()\n",
    "        nmi, acc, ari = 0, 0, 0\n",
    "\n",
    "#         for X_batch, y_batch, _ in train_loader:\n",
    "        X_batch, y_batch = torch.FloatTensor(X_train), torch.Tensor(y_train).type(torch.LongTensor)\n",
    "        y_pred, train_loss = m.fit(X_batch, y_batch)\n",
    "        epoch_loss += train_loss\n",
    "\n",
    "        f1 = f1_score(np.argmax(y_pred, axis=1), y_batch)\n",
    "        acc = roc_auc_score(y_batch, y_pred[:,1])\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_f1 += f1.item()\n",
    "\n",
    "\n",
    "        m.classifier.eval()\n",
    "        val_pred = m(torch.FloatTensor(X_val).to(args.device))\n",
    "        val_loss = nn.CrossEntropyLoss(reduction='mean')(val_pred, torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "        val_f1 = f1_score(torch.argmax(val_pred, axis=1), y_val)\n",
    "        val_auc = roc_auc_score(y_val, val_pred[:,1].data.cpu().numpy())\n",
    "        es([val_f1, val_auc], m)\n",
    "\n",
    "        print(f'Epoch {e+0:03}: | Train Loss: {epoch_loss/len(train_loader):.5f} | ',\n",
    "            f'Train F1: {epoch_f1/len(train_loader):.3f} | Train Acc: {epoch_acc/len(train_loader):.3f}| ',\n",
    "            f'Val F1: {val_f1:.3f} | Val Acc: {val_auc:.3f} | Val Loss: {val_loss:.3f}')\n",
    "\n",
    "        if es.early_stop == True:\n",
    "            break\n",
    "\n",
    "\n",
    "    ###################################### Testing #####################################\n",
    "\n",
    "    print(\"\\n####################################################################################\\n\")\n",
    "    print(\"Evaluating Test Data\")\n",
    "\n",
    "    # Load best model trained from local training phase\n",
    "    m = es.load_checkpoint(m)\n",
    "    m.classifier.eval()\n",
    "    test_pred = m.classifier(torch.FloatTensor(X_test))\n",
    "    test_loss = nn.CrossEntropyLoss(reduction='mean')(test_pred, torch.Tensor(y_test).type(torch.LongTensor))\n",
    "\n",
    "    test_f1 = f1_score(np.argmax(test_pred.detach().numpy(), axis=1), y_test)\n",
    "    test_auc = roc_auc_score(y_test, test_pred[:,1].detach().numpy())\n",
    "    f1_scores.append(test_f1)\n",
    "    auc_scores.append(test_auc)\n",
    "    \n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {epoch_loss/len(train_loader):.5f} | ',\n",
    "        f'Train F1: {epoch_f1/len(train_loader):.3f} | Train Acc: {epoch_acc/len(train_loader):.3f}| ',\n",
    "        f'Test F1: {test_f1:.3f} | Test Acc: {test_auc:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "\n",
    "#     reg = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "#     reg.fit(X_test, y_test)\n",
    "#     best_features = np.argsort(reg.feature_importances_)[::-1][:10]\n",
    "#     print(\"Best Features \")\n",
    "#     print(column_names[best_features])\n",
    "#     print(\"=========================\\n\")\n",
    "print(f1_scores, auc_scores)\n",
    "print(\"Avg. Test F1 = {:.3f}, AUC = {:.3f}\".format(np.average(f1_scores), np.average(auc_scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
